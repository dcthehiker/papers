
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>jennions-et-al-2023-toward-the-aircraft-of-the-future-a-perspective-from-con</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="1" id="mark-3fb24f48-adb8-4d1d-8b70-527f104a85b5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><h1><div><div>Toward the Aircraft of the Future: A Perspective from Consciousness</div></div></h1><div><br></div><div><div><div>Cordelia Mattuvarkuzhali Ezhilarasu <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="282" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>∗</mo></mrow></msup></math></mjx-assistive-mml></mjx-container> ,Jim Angus <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="283" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2217"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>∗</mo></mrow></msup></math></mjx-assistive-mml></mjx-container> and Ian K. Jennions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="284" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2021"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>‡</mo></mrow></msup></math></mjx-assistive-mml></mjx-container> IVHM Centre, Cranfield University, Bedfordshire, MK43 0AL, UK *c.m.ezhilarasu@cranfield.ac.uk <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="285" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2020"></mjx-c></mjx-mo></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mo>†</mo></mrow></msup></math></mjx-assistive-mml></mjx-container> j.angus@cranfield.ac.uk #i.jennions@cranfield.ac.uk Received 20 May 2023 Revised 18 August 2023 Accepted 29 August 2023 Published 27 September 2023</div></div></div><div><br></div><div><div><div>This paper envisions the possibility of a Conscious Aircraft: an aircraft of the future with features of consciousness. To serve this purpose, three main fields are examined: philosophy, cognitive neuroscience, and Artificial Intelligence (AI). While philosophy deals with the concept of what is consciousness, cognitive neuroscience studies the relationship of the brain with consciousness, contributing toward the biomimicry of consciousness in an aircraft. The field of AI leads into machine consciousness. The paper discusses several theories from these fields and derives outcomes suitable for the development of a Conscious Aircraft, some of which include the capability of developing "world-models", learning about self and others, and the prerequisites of autonomy, selfhood, and emotions. Taking these cues, the paper focuses on the latest developments and the standards guiding the field of autonomous systems, and suggests that the future of autonomous systems depends on its transition toward consciousness. Finally, inspired by the theories suggesting the levels of consciousness, guided by the Theory of Mind, and building upon state-of-the-art aircraft with autonomous systems, this paper suggests the development of a Conscious Aircraft in three stages: Conscious Aircraft with (1) System-awareness, (2) Self-awareness, and (3) Fleet-awareness, from the perspectives of health management, maintenance, and sustainment.</div></div></div><div><br></div><div><div><div>Keywords: Consciousness; conscious aircraft; aircraft maintenance; health monitoring; autonomous systems; self-aware; machine consciousness; philosophy; cognitive neuroscience.</div></div></div><div><br></div><h2><div><div>1. Introduction</div></div></h2><div><br></div><div><div><div>Natural phenomena provide a very strong driver of curiosity and inspiration for humankind. From Velcro inspired by cocklebur seeds entangled with woolen fabric</div></div></div><div><br></div><h2><div><div>* Corresponding author.</div></div></h2><div><br></div><div><div><div>This is an Open Access article published by World Scientific Publishing Company. It is distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 (CC BY-NC-ND) License which permits use, distribution and reproduction, provided that the original work is properly cited, the use is non-commercial and no modifications or adaptations are made. [Velcro, 2022] to wind turbine blades designed after Humpback whales [Locke, 2015], and from silk inspired by the silkworm, and the umbrella based on lotus leaves [Schreiner, 2019], to multi-robot systems operating based on swarm intelligence [Senanayake et al., 2016], these examples of bio-inspired technologies (aka Biomi-micry) are extensive. With respect to aviation, the influence of natural phenomena can be found as early as the first glider developed by Le Bris, who designed it by observing albatross and termed the force of lift as "aspiration" [Lucan, 2007]. Some of the latest examples include Airbus' fello'fly, which was designed to demonstrate the viability of two aircraft flying close together, drawing inspiration from the V-shaped flight pattern of migrating geese [Airbus, 2019], and the simplified design of electrical aircraft (Lilium jet), inspired by manta rays [Lilium, 2019].</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="2" id="mark-22f1c46b-4930-482d-917b-5b6412a12683" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>Learning from natural phenomena not only rests with structural design and operational mechanisms for the technologies but also extends to the computational "thought and action" process, which is mainly based on mammalian and, especially, human nature. The field of Artificial Intelligence (AI) is inspired by natural/human intelligence: artificial neural networks are based on biological neural networks, expert systems emulating human experts in a given field, and Machine Learning (ML) algorithms automatically "learn" the underlying patterns of data, while research on machine consciousness attempts to understand the basis of human consciousness for its synthetic emulation.</div></div></div><div><br></div><div><div><div>The application of AI in developing intelligent systems has made a worldwide impact in both industry and academia. In the aviation sector, AI has become a part of every stage of the aircraft lifecycle, from design and development to operations and sustainment. Most importantly, AI is helping the transition of the decision-making processes involved in different stages, from human-centered to automated and autonomous processes. An example is the recent research by Boeing on autopilot, which is being advanced with autonomous features, making flying without pilots a possibility [Stewart, 2017].</div></div></div><div><br></div><div><div><div>For the maintenance and operation of these complex aircraft, a relatively new capability, Integrated Vehicle Health Management (IVHM) has emerged. It enables the condition-based maintenance of aircraft by reliably assessing and predicting the health of components and systems, scheduling customized maintenance and preventing any surprises (unscheduled maintenance), which would otherwise result in a delayed or cancelled flight [Ezhilarasu and Jennions, 2021]. The "sense-acquire-transfer-analyze-act" processes of IVHM use state-of-the-art sensors and communication technologies, along with advanced AI algorithms for diagnosis and prognosis of the system's health and remaining useful life, based on which sustainment plans, including maintenance and supply chain logistics, are developed [Pomfret et al., 2011]. IVHM systems are proving increasingly popular with increasing research and development being undertaken to improve their capabilities. The scope is across the full aircraft, from base level components, through systems, to overall vehicle level health management and reasoning. This is to ensure the availability of the aircraft by planning the maintenance activities precisely, together with the required logistics.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="3" id="mark-fb0a37a5-597f-41f7-a96f-eb1bc8dffc2d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>The capabilities of an aircraft health management system are easily comparable with a human's capability to sense, be aware of, and to communicate one's health status. Thus, the pursuit of a more intelligent, more efficient, and a more human-like aircraft has led the research world to ponder over questions like: "what if an aircraft could communicate like a human?", "what if an aircraft was aware of its own health and could take necessary actions?" and "what if an aircraft was conscious?". It is the purpose of this paper to address this last question.</div></div></div><div><br></div><h4><div><div>1.1.The Conscious Aircraft</div></div></h4><div><br></div><div><div><div>The initial concept of a Conscious Aircraft was developed over the last few years in Cranfield University's IVHM Centre by Jennions and Angus [Jennions et al., 2022; Jennions and Angus, 2022a, 2022b; Angus and Maggiore, 2022; The Economist, 2022]. It was proposed to explore the possibility of an aircraft with a human-like nervous system, aware of its own health and covered in skin that helps it to sense the damage and changes in the external environment [Jennions and Angus, 2022c; Jennions, 2021]. The use of the term conscious allows aircraft to be thought of as human. So, the analogy between a doctor and a human and maintenance personnel and an aircraft was brought to bear, where a Conscious Aircraft has the ability to set up its own maintenance appointments, just like a human consults with a doctor regarding their health [The Economist, 2022].</div></div></div><div><br></div><h3><div><div>1.2. Motivation for this study and roadmap</div></div></h3><div><br></div><div><div><div>Building on the initial concept of the Conscious Aircraft, this paper aims to investigate the different perspectives of the term consciousness and extrapolate the relevant features to seek to address the question of: what would a Conscious Aircraft be like? The motivation of this review paper is neither to claim a replication of human consciousness nor to articulate and categorize all the many views of consciousness. It is rather a high-level view of the main messages that come out of this intriguing field and how they ultimately could be used effectively to enhance civil aircraft operation and maintenance.</div></div></div><div><br></div><div><div><div>While consciousness is a widely discussed topic in various fields ranging from theoretical physics to politics [Rovelli, 2022a; Tegmark, 2015], this paper has identified three key areas contributing significantly to the research on consciousness as shown in Fig. 1: (i) Philosophy, (ii) Cognitive Neuroscience, and (iii) Machine Consciousness and AI. The field of philosophy discusses consciousness as a phenomenon and has contributed to several ideas influencing the biomimicry of consciousness. Cognitive neuroscience explores the relationship between the brain and consciousness and derives the features which are important for consciousness. The fields of machine consciousness and AI try to identify and develop consciousness synthetically.</div></div></div><div><br></div><div><div><div>Because of the enormity of the fields involved, this paper reviews a non-exhaustive list of significant theories and attempts to derive some key outcomes that could be significant for creating a paradigm-shift in aviation. With this objective, Sec. 1 of the paper provides the motivation for this study. Section 2 presents the general/colloquial meanings of the term consciousness. Section 3 provides the major philosophies underlying the several debates on (natural) consciousness and narrows down on the theories that influence the biomimicry of consciousness. Section 4 reviews the popular cognitive neuroscience theories of consciousness, exploring the ideas around the brain's contribution to consciousness, and derives the important features of consciousness that could contribute to the Conscious Aircraft. Section 5 reviews the development of AI through key milestones and showcases some important ideas presented about artificial or machine consciousness, including autonomy. Section 6 proposes different stages involved in conceptualizing a Conscious Aircraft, based on the key outcomes derived from Secs. 2-5 and from a futuristic aircraft operations and maintenance points of view, followed by the summary and conclusion of the paper in Sec. 7.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="4" id="mark-4babcefa-8b7b-47b3-8909-424ad09475d6" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: Cognitive What is the relationship between the brain and science consciousness? Artificial Intelligence /Machine Conscious ness Can consciousness be generated? Neuro- Consciousness Philosophy What is Consciousness? --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_3.jpg?x=434&amp;y=306&amp;w=689&amp;h=685&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_3.jpg?x=434&amp;y=306&amp;w=689&amp;h=685&amp;r=0"><div><br></div><div><div><div>Fig. 1. Key fields underlying consciousness chosen for the study.</div></div></div><div><br><!-- Media --><br></div><h2><div><div>2. Several perspectives of Consciousness and Self-Consciousness</div></div></h2><div><br></div><div><div><div>This section presents the general/colloquial meanings of the term consciousness and discusses the various perspectives of consciousness and self-consciousness. This facilitates understanding of the distinction between the outer and the inner concepts of consciousness and self-consciousness. These concepts are referred to as intelligence and experience, respectively. Differences between intelligence and experience influence the fields of cognitive neuroscience, AI and machine consciousness, and consequently influence the development of the Conscious Aircraft.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="5" id="mark-8050eb8d-b1ef-4bad-8768-0ceb79ba0821" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h3><div><div>2.1. Consciousness</div></div></h3><div><br></div><div><div><div>The term consciousness has been used in a variety of contexts through the centuries. The etymology of the term can be traced back to the Latin word conscio, meaning: knowing, aware. In its original Latin sense, to be conscious of something was to possess knowledge, to share knowledge of it with someone else or with oneself [Zeman, 2001]. The origin of the modern concept of consciousness is attributed to Locke's (1690) definition as "the perception of what passes in one's own mind" [Coventry and Kriegel, 2008].</div></div></div><div><br></div><div><div><div>Zeman [2001] points out the three principal meanings used for the term consciousness, which are widely adapted across different fields:</div></div></div><div><br></div><div><div><div>(i) Consciousness as the waking state: In a neurological context, consciousness refers to the degree from waking through sleep into a coma. In this case, to be conscious is to be awake, alert, or vigilant, interacting with the external environment in an integrated way, e.g., X has regained consciousness, Y has lost consciousness.</div></div></div><div><br></div><div><div><div>(ii) Consciousness as experience: This describes "what it feels like" to experience something; the content of the experience or awareness. This is referred to as qualia by some philosophers and is often referred to as the subjective/personal point of view, e.g., A is conscious of a feeling of pain.</div></div></div><div><br></div><div><div><div>(iii) Consciousness as mind, echoing the Latin conscientia, referring to the awareness of mental state, e.g., B is conscious of their performance.</div></div></div><div><br></div><div><div><div>Over the course of time, consciousness was referred to more in the first two contexts: the degree of wakefulness and the content of experience, as the third state was more synonymous with mind/mindfulness. There are several alternating concepts revolving around the meaning of consciousness, as seen in Fig. 2, which, as far as is possible, forms a summary of this section. Beginning at the top right of Fig. 2, and proceeding anti-clockwise, the two different contexts mentioned above are wakefulness and awareness. Consciousness as an experience and as a wakeful state provides two different perspectives on the same subject: (i) the inner concept of consciousness, where it is seen as a determinate, private, invisible, and crucial internal process or event (experience), and (ii) the outer concept of consciousness, a sophisticated form of interaction with the world, an elaborate process of exploration, intelligent behavior [Zeman, 2006]. This forms the top-center bubble of Fig. 2.</div></div></div><div><br></div><div><div><div>The two polar-opposite perspectives — a subjective/first-person and an objective/third-person outlook of consciousness - are the foundation of most of the debates surrounding the subject of consciousness, especially the philosophical debate around the hard problem and the easy/soft problem (bottom left bubble of Fig. 2). As Chalmers distinguished between two phenomena, the easy (or soft) problem of consciousness is to understand and explain how biological processes contribute to different psychological functions of consciousness, and the hard problem is to explain scientifically the experience of "something that is like" [Chalmers, 1996, 2017]. An example of the latter is the famous philosophical question posed by Nagel [1974]: what is it like to be a bat? The "feeling like to be something" or the subjective experience is also referred to as qualia, phenomenal consciousness, or phenomenality [Block, 2006].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="6" id="mark-e50da08e-6ccd-467c-8202-6f4107b357f1" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: First-person Awareness perspective) vs (subjective) vs Wakefulness perspective) (Objective) Consciousness Neurological perspectives Phenomenal Inflationist views vs consciousness Deflationist views vs Access Consciousness Experience (Inner outlook vs Third-person Intelligence (outer outlook Philosophical perspectives Hard problem vs Easy problem vs Real problem vs Meta problem --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_5.jpg?x=283&amp;y=295&amp;w=981&amp;h=708&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_5.jpg?x=283&amp;y=295&amp;w=981&amp;h=708&amp;r=0"><div><br></div><div><div><div>Fig. 2. Various alternative views on consciousness.</div></div></div><div><br><!-- Media --><br></div><div><div><div>There are again several opinions on the basis of the hard and easy problems; they are generally grouped into deflationist and inflationist views (bottom-center bubble of Fig. 2) [Block, 2006]. Deflationists view consciousness as something that can be reduced conceptually or philosophically to function, representation, or cognition. They consider that the hard problem can be eventually dissolved into easy problems, which can be explained scientifically [Safron, 2020]. Consciousness can be seen as any other scientific problem, such as the physical or functional basis of liquidity or inheritance, thus ruling out any mysteries around this concept. On the other hand, inflationists share the view that consciousness cannot be reduced conceptually or philosophically. Inflationism accepts the hard problem of consciousness and considers it to have a causal role, aiming to bring the empirical solution as the science of consciousness advances [Block, 2006]. There are also suggestions that these philosophical questions divert the scientific community from the more important endeavor of studying the relationship and reasoning between particular experiences associated with particular physical processes, commonly referred to as the real problem (bottom-left bubble of Fig. 2). The disagreements about the hard problem have given rise to more philosophical questions, labeled by Chalmers as the meta problem [Safron, 2020]. From a cognitive neuroscience perspective, the understanding of consciousness is framed into areas such as "what is the neural basis of experience?" or phenomenal consciousness, and "what makes the neuronal representations available for thought, decision, and action?" or access consciousness [Block, 2006] (bottom-right bubble of Fig. 2).</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="7" id="mark-20aa47a4-04ff-454e-b146-6e76a3a339d3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>In addition to the questions and challenges highlighted in this section, there are many more questions that arise regarding consciousness, some of which are bravely collated and grouped into categories by Niikawa [2020]. This work serves to illustrate the diversity and lack of agreement regarding the subject.</div></div></div><div><br></div><h3><div><div>2.2. Self-consciousness</div></div></h3><div><br></div><div><div><div>The debate around self-consciousness is similarly referred to in different contexts. It can be defined as the awareness of one's own physical form in a time-space continuum and its interaction with the environment, including others [Keromnes et al., 2019]. Self-consciousness also includes the awareness of one's identity built over time in interaction with others. The idea of self gives rise to high-level processes like the Theory of Mind or empathy [Keromnes et al., 2019]. In psychology, the Theory of Mind is the ability to attribute one's mental state to self and others, forming the basis of social interaction. This encompasses the understanding that one's mental state can be different from that of others. The core mental states contributing to the Theory of Mind are attention, intention, and imitation [Ruhl, 2020]. According to Lewis [2003], from a human development point of view, Theory of Mind is acquired in four stages: (1) I know (prevalent among children, adults, and animals), (2) I know I know (idea of self; memory of a memory; develops in children from 2.5 years), (3) I know you know (the mental state of believing that others know what one knows; develops around the same time as Stage 2), and (4) I know you know I know (perspectives of self and others; this is an adult-like level) [Lewis, 2003]. Theory of Mind has been instrumental in developing some cognitive neuroscience theories (as can be seen in Sec. 4.1) and machine consciousness theories (as can be seen in Sec. 5.1.3).</div></div></div><div><br></div><div><div><div>The term self-consciousness requires a representation of self and others in order to behave differently toward the former and the latter. Zeman [2006] also provides six different representations of the term "self-consciousness", which are:</div></div></div><div><br></div><div><div><div>(i) Proneness to embarrassment: In this representation, self-consciousness refers to being excessively aware of the awareness of others toward oneself, e.g., X is self-conscious of Y's opinion about X's actions.</div></div></div><div><br></div><div><div><div>(ii) Self-detection: An organism is self-conscious if it can respond to external stimuli and act upon them directly or indirectly, implying awareness of its own actions, e.g., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="286" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container> is self-conscious of its hunger.</div></div></div><div><br></div><div><div><div>(iii) Self-monitoring: This is an extension of self-detection to the past and the future, e.g., <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="287" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44B TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>X</mi></math></mjx-assistive-mml></mjx-container> is self-conscious of its need for food every few hours.</div></div></div><div><br></div><div><div><div>(iv) Self-recognition: One's ability to recognize oneself in the mirror. Chimpanzees, monkeys, and babies from 18 months are self-conscious of themselves while looking at mirrors.</div></div></div><div><br></div><div><div><div>(v) Awareness of awareness: One's ability to be aware of oneself being a subject of experience. Babies from 18 months to 5 years start recognizing not only their physical appearance but also their mental/subjective experience.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="8" id="mark-4c8a1183-8a05-4e74-9d16-b2015e8a1942" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>(vi) Self-knowledge: This is the ultimate representation of self-consciousness, which is one's knowledge of oneself to be the hero of one's personal narrative. Having self-knowledge is the capability to relive past information through mental time travel, e.g., X is self-conscious of how hungry they can be without food.</div></div></div><div><br></div><div><div><div>Consistent with the different perspectives of consciousness, the first three representations focus on the outer concept, where the self is in reference to others and the outside environment, and the last three representations focus on the inner concept, where the self is in reference to oneself. It is evident that the concept of "self" is conceivable only when the subject of "others" (including the environment) is brought into the picture. This resembles the extended view of the Nobel Laurate Neil Bohr on quantum mechanism: "The unambiguous description of any phenomenon requires the inclusion of all the objects involved in the interaction in which the phenomenon manifests itself" [Rovelli, 2022a].</div></div></div><div><br></div><div><div><div>This section identified that the inner and the outer concepts (i.e., experience and intelligence) are applicable for both consciousness and self-consciousness. The idea of 'Self' which includes the subject of 'others' is an important concept, which can be used for the Conscious Aircraft, in order to recognize itself and differentiate from the others. Also, the different states of Theory of Mind in developing the concept of "self" and "others" can be used in defining the stages of developing a Conscious Aircraft in the later sections of this paper.</div></div></div><div><br></div><h3><div><div>3.The Philosophical Background of Consciousness</div></div></h3><div><br></div><div><div><div>Consciousness is one of the most debated topics in the world of philosophy. The main focus of philosophers is on the origin of consciousness: whether it is attributed to a physical or a mental form (the mind-body problem) or both, and whether its origin is dependent or independent of a biological form. There are several philosophical views on consciousness. Figure 3 collates the spectrum of philosophical views, with the vertical axis dividing immaterialistic (doesn't require any medium) and materialistic (requires physical/biological medium) views. The horizontal axis is split between mental, physical, and artificial mediums. A non-exhaustive list of different philosophical views is discussed in this section and is arranged, across the background of Fig. 3, accordingly.</div></div></div><div><br></div><div><div><div>Dualism: Dualism (seen in the middle of Fig. 3) posits that consciousness can be attributed to two separate entities: objective physical and subjective mental substances [Robinson, 2020]. From the classical yoga perspective of "objective body and subjective mind" [Hanley, 2002] to Descartes' famous saying, "I think, therefore I am" in 1641 [Smith, 2015], dualism (or variations on it) is the most prominently held view of consciousness across centuries in both eastern and western philosophies. Modern-day dualism explores consciousness on the basis that consciousness is correlated to neural activities, but that they are both distinct phenomena [Zeman, 2001]. As mentioned in Sec. 2, Chalmer's hard and easy problem classification is one of the famous arguments made about consciousness from a dualist's perspective [Chalmers, 2011].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="9" id="mark-03b2f7fa-65e5-4863-a66b-17a3e75b0aa3" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: Materialistic realm Materialism (Functionalism) Materialism (Identity theory, Eliminative Theory Behaviorism) Property Dualism Cartesian Dualism * Idealism and Materialism are two forms of Monism Physical Artificial Idealism (Solipsism) Immaterialistic realm Idealism (Cosmic Consciousness, Panpsychism) Mental --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_8.jpg?x=184&amp;y=296&amp;w=1174&amp;h=817&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_8.jpg?x=184&amp;y=296&amp;w=1174&amp;h=817&amp;r=0"><div><br></div><div><div><div>Fig. 3. Philosophical theories of consciousness.</div></div></div><div><br><!-- Media --><br></div><div><div><div>Among different views of dualism, Cartesian or Substance dualism grounds consciousness in materialistic physical substance and immaterialistic mental substance, whereas Property Dualism grounds consciousness to only physical substance, but with physical and mental properties [Robinson, 2020]. For example, according to Cartesian dualism, a living organism can be a substance with certain properties, but it will still continue to be the same organism (on the inside) with alteration to those properties [Calef, 2021]. On the other hand, an example of a type of property dualism, called Epiphenomenalism, is that a mental property (fear) can be a result of a physical property (increase in adrenaline, resulting in an increase in heartbeat) [Walter, 2021] and this mental property does not have any causal power over physical events. According to epiphenomenalism, a conscious experience is the result of information processing in the brain. In general, dualism claims that mind and body are two distinct phenomena and that consciousness is mainly attributed to this mental phenomenon, irrespective of its origin or nature.</div></div></div><div><br></div><div><div><div>Monism: In contrast with dualism, monism assumes that there is only one realm of existence. In monism, Idealism considers that only the mind exists, and in that, Solipsism believes that only one's mind exists [Guyer and Horstmann, 2021]. An example of idealism is the theory by Kastrup (computer scientist and philosopher) that there is only Cosmic Consciousness, and all living organisms are its dissociated alters, surrounded by thoughts [Kastrup, 2019]. Another form of monism, Panpsychism, claims that everything that exists in the world/universe has mentality [Goff et al., 2022]. This is in alignment with views of many western and eastern philosophies, e.g., the Greek philosopher Thales claimed that a magnet has a mind as it moves itself toward an object [Goff et al., 2022], and a Hinduism philosophy, Advaita claimed "all that exists is absolute consciousness" [Menon, 2021]. Philosophers arguing for panpsychism have different opinions regarding the object and mind, as to whether everything in the universe has mentality or everything in the world has mentality, and whether mentality refers to a universal property or is in the mind of the object [Skrbina, 2021]. One of the popular theories of cognitive neuroscience, Integrated Information Theory (IIT), is philosophically associated with panpsychism, even though there are no scientific details on their direct association [Albantakis, 2020].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="10" id="mark-c77cd08f-fbb2-49a2-a5bb-f1d433ba8400" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>Among other types of monism, materialism is the philosophy that is followed mostly by scientists, since materialism attributes consciousness to the physical world. According to materialism, everything that exists is made up of physical substance, and hence, this ideology is at the opposite end of the idealism spectrum. Materialism has influenced ideologies like Dialectical Materialism (the underlying philosophy of Marxism by Karl Marx and Freidrich Engels), and Machism (by Ernst Mach, the scientist known for Mach number). Marx and Engels developed Dialectical Materialism, which considers knowledge as a part of concrete human history and acquiring knowledge is an ongoing process [Rovelli, 2022a]. Mach suggested that knowledge should be based on what is observable. According to Mach, knowledge is possessed not by abstract idealism (e.g., knowledge is fundamental or universal), but through concrete human activity and by learning to better organize the facts of the world with which it interacts. Mach's idea of knowledge shares commonality with Marxism [Rovelli, 2022a], and this brought him into a dispute with Lenin, who considered Mach's idea as Solipsism [Rovelli, 2022a].</div></div></div><div><br></div><div><div><div>While philosophers of materialism agree that there are no two different things such as physical and mental properties as suggested by dualists, they disagree upon what type of physical properties constitute the mental states. One of the prominent forms of materialism in the 20th century is Identity Theory, also called Type Physicalism. Identity theory claims that mental properties can be reduced to physical properties (e.g.,pain associated with c-fiber <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="288" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c61"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">a</mi></mrow></mrow></msup></math></mjx-assistive-mml></mjx-container> excitation),thus providing a retort to the mind-body problem posed by the dualists [Schneider, 2021]. The mind is considered an electrochemical state of biological neural networks [Reggia, 2013]. In the same way as scientifically understanding light in the form of electromagnetism, and heat in the form of the kinetic energy of atoms, identity theory suggests that consciousness can be scientifically understood as neural events. However, while scientifically analyzing the physical properties of these phenomena can be done objectively, the same cannot be claimed for analyzing the subjective experience [Zeman, 2001]. Other types of materialism exist, such as Behaviorism which considers mental states to be a result of behavioral disposition, and Eliminative Materialism which suggests that the current common sense psychological concepts or "folk psychology" should be eliminated in favor of correct scientific explanations from neuroscience [Reggia, 2013].</div></div></div><div><br></div><hr><div><br><!-- Footnote --><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="289" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44E TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mi>a</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> C-fiber belongs to one of the three nerve groups of the central nervous system and peripheral nervous system. C-fibers respond to strong intensities and are characterized by small diameter and low conduction velocity. Hence, they account for slow, lasting and spread out pain [Yam et al., 2018].</div></div></div><div><br><!-- Footnote --><br></div><hr><div><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="11" id="mark-16002824-349c-4296-95d3-339b7f0e283c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><div><div>The type of materialism that has paved the way for research on machine consciousness is functionalism. It considers mental states as corresponding to the brain, and the nature of mental states being due to their functionality and not their physical properties [Polger, 2021]. The essence of the mental state lies in the function of the state (what it does) rather than the physical nature (what it is made of). For example, while the mouth is a physical object, its functional states include talking, eating, and emoting. Dennett, a notable philosopher and one of the champions of functionalism, cites that the activity of the brain is analogous to the implementation of a software package in a computer to create a functioning machine [Zeman, 2001]. Such comparisons have encouraged many scientists to work toward developing machines with artificial consciousness since the analogy between brain and computer brings in the picture of the brain being replaced by computer hardware as the physical substrate that can execute the functionality of consciousness through its software, thus leading to machine consciousness [Reggia, 2013]. Despite the positive outlook toward machine consciousness, it is argued, similar to identity theory, that functionalism can manage to solve only the easy problem posed by Chalmers, which is to explain the psychological functions of consciousness. But the hard problem of explaining the occurrence of experience or qualia is still facing an explanatory gap in functionalism [Reggia, 2013; Zeman, 2001].</div></div></div><div><br></div><div><div><div>There have also been several suggestions to replace this philosophical framework of considering consciousness in either a dualistic, idealistic or materialistic view, especially by theoretical physicists. Rovelli, in his book on quantum physics called Helgoland, claims that untangling the processes that take place in bodies and their relations with the external world can help us understand the phenomenology of consciousness [Rovelli, 2022c]. Similarly, another theoretical physicist, Tegmark, insists consciousness can be understood by physicists deriving consensus reality based on the shared perception by the observers from the external reality of the physical world and by cognitive neuroscientists deriving internal reality of subjective perspective from consensus reality [Tegmark, 2014].</div></div></div><div><br></div><div><div><div>To summarize Sec. 3, there has been no consensus on the definition of consciousness among philosophers over the centuries. The division of opinions about consciousness, whether or not it can be generated artificially and whether creating such artificial systems identical to human beings would be conscious or remain as Philosophical Zombies, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="290" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c62"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">b</mi></mrow></mrow></msup></math></mjx-assistive-mml></mjx-container> still exists [Montemayor,2021]. However,with respect to the Conscious Aircraft, the functionalist point of view that consciousness is a function of the human brain, leads directly to the next section on cognitive neuroscience, to explore the possibilities of biomimicry of consciousness in an aircraft.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="12" id="mark-6ac38e33-c901-4833-a404-9818e1897774" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><h2><div><div>4. Cognitive Neuroscience Theories of Consciousness</div></div></h2><div><br></div><div><div><div>Cognitive neuroscience studies the biological processes underlying cognition and examines how brain functions support mental activities [McClelland, 2001]. This field aims to address questions about the brain's relationship with consciousness, its emergence, and the functioning of consciousness. This section presents a few selected theories of consciousness from cognitive neuroscience to understand the relationship between the brain and consciousness. All these theories have experiments and applications in the field of medical science, ranging from the detection of awareness in blindsight <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="291" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c63"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">c</mi></mrow></mrow></msup></math></mjx-assistive-mml></mjx-container> patients to the detection of consciousness in minimally conscious, vegetative, and comatose patients. To stay within the scope of this paper the examples of applications for the reviewed scientific theories in this section will only be from the engineering and computer science fields. More detailed reviews on theories of consciousness are available [Seth and Bayne, 2022; Zeman, 2001].</div></div></div><div><br></div><div><div><div>A summary of the scientific theories of consciousness presented in this section is given in Table 1, along with the outcomes from each for a Conscious Aircraft. Each of these theories (columns in Table 1) has a different view on what constitutes a conscious experience and which parts of the brain, and the body are linked with consciousness. Table 1 also lists the AI applications derived from these theories and the main takeaways from them which will help derive the features of the Conscious Aircraft in the later sections of the paper. The rest of this section will discuss the theories in each column of Table 1 in order.</div></div></div><div><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="292" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D44F TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mi>b</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> Philosophical Zombies is a thought experiment in philosophy of mind,in which,the hypothetical beings (zombies) are identical to human beings functionally but cannot have conscious experience or qualia. Dualists use philosophical zombies argument to claim that consciousness cannot have physical nature, and it is completely associated with mental phenomena, since zombies can physically carry out all functions of a normal human, but will still not be conscious. Functionalists like Dennett claim that zombies are incoherent and hence cannot be compared with a normal human [Kirk, 2021].</div></div></div><div><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="293" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D450 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mi>c</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> Blindsight is a condition in which the sufferer responds to visual stimuli without consciously perceiving them [Weiskrantz, 2007]. The term was first coined by Weiskrantz in 1974, to describe a fractured conscious state in a patient who claimed to be half blind after brain surgery, was not able to see anything beyond his left side of the nose but was still able to identify objects in that area with around <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="294" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>80</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> accuracy. Despite the patient's blindness, his healthy eyes were still watching the world and passing the information to his unconscious, which was guiding his behavior. In other words, the patient with blindsight can still perceive information but would lack awareness of perception (or subjective experience). This concept has made some philosophers claim that humans are little more than "zombies" acting on mostly unconscious impulses [Robson, 2015].</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="13" id="mark-fd3899c2-50ba-4802-be35-b0b86ecd611c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br></div><div><div><div>Table 1. Comparison between different theories of consciousness.</div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td></td><td>Radical plasticity thesis</td><td>Global work- space theory</td><td>Integrated world model theory</td><td>Default space theory</td></tr><tr><td>Principle</td><td>System forms a the- ory about itself and cares (emotionally)</td><td>The brain is a series of processors</td><td>Cause/effect probabil- istic system models with forward trajectories</td><td>All of the body contributes to a model tested against sensory data</td></tr><tr><td>AI applications</td><td>Meta-cognitive neural nets with second nets checking hidden layers</td><td>Blackboard and intelligent agent archi- tectures</td><td>Autoencoders for information in Self-Organizing Harmonic Modes (SOHMs)</td><td>None known</td></tr><tr><td>Conscious Aircraft ideas</td><td>Conscious Aircraft needs to learn about self and other aircraft in the fleet, while caring about the outcomes</td><td>Conscious Air- craft using Global Work- space archi- tecture with unconscious modules</td><td>Conscious Aircraft needs to be auton- omous and self- aware. Needs world model (digi- tal twins) for counterfactual simulations</td><td>Conscious Aircraft needs to consider sensory data from all sources for its world model (digital twins)</td></tr></tbody></table></div><br><!-- Media --><br></div><h4><div><div>4.1.The Radical Plasticity Thesis</div></div></h4><div><br></div><div><div><div>This theory by Cleeremans suggests that consciousness arises as a result of the brain's continuous attempt at predicting the consequences of its actions both externally (on the world and other agents) and internally (impact on other parts of the brain) [Cleeremans, 2011]. According to the Radical Plasticity Thesis, consciousness depends on three core ideas:</div></div></div><div><br></div><div><div><div>(i) Quality of Representation (QoR): It is the graded property that determines the extent to which a representation is available to influence behavior, form the contents of awareness, and be the object of cognitive control and other high-level processes. QOR is represented in terms of stability, strength, and distinctiveness.</div></div></div><div><br></div><div><div><div>(ii) Meta Representation: Higher-order representations give a cognitive system the ability to learn about its own representation; they can also be used to anticipate the future occurrences of first-order representations. A conscious representation is when one is aware that one is conscious of the representation. Thus, awareness is linked with knowledge of the consequences of an action. A system's ability to redescribe its own knowledge (representational redescription) to itself depends on the existence of recurrent structures that enable the system to access its own states. It also depends on the existence of predictive models (meta-representations) that make it possible for the system to characterize and anticipate the occurrence of first-order states. Conscious awareness proceeds from top to bottom, i.e., a system is aware of the higher-level concept of a scene at first, before becoming aware of its lower-level features.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="14" id="mark-caa81efd-5781-4bc2-a836-eb4fc425327d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>(iii) Theory of Mind is one's ability to represent the mental state of other agents. The system's ability to redescribe its own representations to itself depends on the system's interaction with other systems similar to itself. A system is conscious not only because it can have an understanding of its actions toward a goal but also to understand how similar systems react to those actions directed toward them: learning from the behavior of others [Cleeremans, 2011].</div></div></div><div><br></div><div><div><div>Thus, the brain continuously learns to anticipate the effect of its own activities on the environment, and itself, unconsciously. The conscious experience is rooted in the practical knowledge accumulated through these interactions. In other words, consciousness is the brain's theory about itself, gained through experience interacting with the world, other agents and itself. This theory's central claim is that learning, or plasticity (hence the theory's name), makes us conscious [Cleeremans, 2011].</div></div></div><div><br></div><div><div><div>This theory also suggests that emotion is crucial to learning. A conscious experience for a system includes learning the geography of its own representations and to care about the experiences, for there is no sense in a system learning about anything if the learning fails to do something to the system [Cleeremans, 2011]. Caring about the experience is the difference between a person seeing a red patch versus a camera seeing a red patch. While the person can feel emotions and recall memories associated with the experience of seeing redness, a camera could not do the same and hence cannot care about the experience [Cleeremans, 2011].</div></div></div><div><br></div><div><div><div>Several concepts proposed in the Radical Plasticity Thesis could be used for the development of the Conscious Aircraft. This theory emphasizes the importance of representational redescription based on self and others' state of mind and learning from their behavior. The importance of learning about self and others lays the foundation of consciousness (also discussed in Sec. 2), where differentiating the self from others and the environment is a key component of being self-conscious. Thus, by transferring this knowledge to the subject of this paper, for an aircraft to be conscious, it has to continuously learn about its environment, about itself, as well as other (similar) aircraft. Another key takeaway from this theory is that the conscious experience requires emotion to be part of its learning. Hence, along with learning about its own representations, the Conscious Aircraft has to learn to care about the experiences as a mechanism to provide feedback to its systems about its actions and learnt lessons.</div></div></div><div><br></div><h3><div><div>4.2. Global Workspace Theory</div></div></h3><div><br></div><div><div><div>Global Workspace Theory (GWT) was developed by Baars in 1988 [McGovern and Baars, 2007]. This theory hypothesizes that consciousness corresponds to a global workspace that allows unconscious parallel processes in the brain to communicate with informational synergy. GWT is a cognitive architecture with an explicit role for consciousness [Baars and Franklin, 2003]. GWT assumes that the brain can be viewed as a collection of processors. Global workspace is a structure associated with consciousness, and it can be compared with a blackboard architecture in which a set of distributed knowledge sources can cooperatively solve problems together that are otherwise not possible by the single sources [Seth and Bayne, 2022]. From the global workspace, the focal contents compete to be broadcast to many unconscious modules. Some of the unconscious modules like contexts (e.g., motives and emotions are goal contexts) could shape conscious contents and can work together to constrain conscious events [Baars and Franklin, 2003].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="15" id="mark-1c6d5ea9-962f-4b3d-818a-a96405ff53c2" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>An engineering example of a GWT-influenced intelligent agent architecture is shown in Fig. 4. It was developed for autonomous structural health monitoring of aircraft by the United States Airforce Research Laboratory [Derriso et al., 2012]. Since most structural health monitoring research focused on developing quick state assessments (reflexive techniques), which were unreliable in the long term, a more thoughtful deliberative assessment was required for operational-level decisions. For this purpose, the principle of the global workspace was used in developing the intelligent agent architecture.</div></div></div><div><br></div><div><div><div>The experiment was conducted on a representative aircraft component, the wing attachment lug. The intelligent agent architecture was applied to support enhanced state estimation and operational decisions. The perceptual system receives operational and environmental data such as load cycles and temperature profiles, which are used by the state characterization module to generate state estimates for crack detection and length estimation models. This data is also used for context-based decisions by the situated state conceptualization module in the conceptual system, as in Fig. 4. The situated state conceptualization module uses context information and/ or physics-based models to refine the estimates. The state estimates at this stage can make use of specific processes like requesting data processed by secondary methods. It uses predetermined condition-action rules to satisfy the rules of the tasking agent. Finally, the situated deliberation stage provides the goal for the tasking agent based on the context and state estimates. In this experiment of crack length estimation of a wing lug, the situated state conceptualization uses the current crack length estimates and the predicted crack lengths to determine the current selected crack state with a condition-action rule-based algorithm. The situated deliberation stage is used to determine the cycles remaining to failure of the component based on the current crack state. This experiment successfully proved the usefulness of GWT-based intelligent agent architecture in determining the lug crack existence and length estimate, along with the cycles to failure data required for deciding the future mission profile [Derriso et al., 2012]. This example shows the ability of GWT for enabling series and parallel processes to generate context and account qualitatively for the matched pairs of deliberative and reflexive elements [Derriso et al., 2012].</div></div></div><div><br><!-- Media --><br><!-- figureText: Conceptual System Perceptual System Sensors Operational / Environmental Data Processing State Characterization Actuators Situated State Conceptualization Situated Deliberation --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_14.jpg?x=271&amp;y=1575&amp;w=1014&amp;h=472&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_14.jpg?x=271&amp;y=1575&amp;w=1014&amp;h=472&amp;r=0"><div><br></div><div><div><div>Fig. 4. Intelligent agent architecture inspired by Global Workspace Theory for structural health monitoring of aircraft components [Derriso et al., 2012], reproduced with permission; copyright IEEE 2012.</div></div></div><div><br><!-- Media --><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="16" id="mark-c0bf7f45-befe-47d5-a586-01d9e4088be7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><div><div>The key outcome from GWT for a Conscious Aircraft is that a system is capable of consciousness if it can function with a global workspace, coordinating between conscious and unconscious modules. The Conscious Aircraft must be capable of processing distributed knowledge sources (unconscious information) in parallel, for information synergy and context generation, to solve problems that otherwise could not be solved by individual (conscious) sources. In the shorter term, this idea will have wide impact on maintenance problems like No Fault Found (NFF), where processing unconscious information for context generation will provide more clarity on the scenarios which led to faults, even when they are not capable of replication.</div></div></div><div><br></div><h3><div><div>4.3. Integrated World Modeling Theory of Consciousness</div></div></h3><div><br></div><div><div><div>Integrated World Modelling Theory (IWMT) combines three theories: Integrated Information Theory (IIT), Global Neuronal Workspace Theory, and the Free Energy Principle - Active Inference framework, developed to understand consciousness [Safron, 2019, 2020]. IIT postulates that a system is conscious if it is composed of irreducible elements that constrain each other and allow it to have cause-effect power over itself. It suggests that the cause-effect power can be captured by <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="295" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c3A6"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Φ</mi></math></mjx-assistive-mml></mjx-container> ("PHI"),a measure of the information processing capacity of the system. The Global Neuronal Workspace Theory is an extension of GWT, developed by Dehaene, according to which the bottom-up feed forward process of unconscious modules and the top-down feedback processes (attentional amplification) of information are mobilized into a coherent activity by workspace neurons, and they enable faster globalization of information for further processes. This theory assumes that many non-conscious modules can process in parallel and that attention is required for information to enter consciousness [McGovern and Baars, 2007]. Free Energy Principle - Active Inference framework suggests that in order for a system to exist, it must generate mutual probabilistic information between past and future states based on their present conditions, characterizing the system as generative models producing evidence for themselves through their dynamics (self-evidencing), to bound surprise (prediction errors) with respect to predictive models. According to the framework, the singular objective function of a self-evidence model is optimized by minimizing discrepancies between probabilistic beliefs and observations, penalized by model complexity [Safron, 2020].</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="17" id="mark-d53c9fd4-5670-4990-89b9-73c13f16373a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>IWMT's primary focus is to explain how biological systems can generate phenomenality or experience as a subjective view; consciousness as a phenomenal experience. IWMT states that, for an intelligent system interacting with, and embedded in, an environment, consciousness might be the process of evolving probabilistic generative integrated models of systems and environments, with spatial (by comparing with other things in that space), temporal (by comparing the things relative to different timelines), and causal (by comparing the factors constituting the cause) coherence. IWMT suggests that such coherence is likely if and only if such systems are capable of supporting complexes of high degrees of integrated information, functioning as global workspaces and arenas for Bayesian model selection, thus integrating the three theories [Safron, 2020].</div></div></div><div><br></div><div><div><div>IWMT postulates that, for a system to have experience of a world, the system must be able to situate and contrast the things that comprise that world with respect to space, time, and cause. In addition to space, time, and cause, IWMT also suggests that self-processes (to enable learning necessary for developing different models of the world) and autonomy (to help coherent sense-making) are required preconditions for generating subjective experience/phenomenal consciousness, i.e., both access and phenomenal consciousness require generative processes capable of producing counterfactual simulations with respect to selfhood and self-generated actions [Safron, 2020].</div></div></div><div><br></div><div><div><div>IWMT suggests that the global workspaces should have the ability to exert cause-effect power over themselves, with free energy (predictive error) minimized and integrated information <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="296" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c3A6"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Φ</mi></math></mjx-assistive-mml></mjx-container> maximized. This is possible if they are organized hierarchically with modularity, thus enabling robustness, separable optimization and balanced integration and differentiation. The theory proposes that the complexes of integrated information and global workspace emerge as SOHMs through continuous engagement with environments (rich causal world models), generating coherent and precise inference. These SOHMs align patterns shaping definite experiences from probabilistic world models, thus promoting "communication through coherence". This continuous shaping of behavior is a major adaptive function of consciousness as well as a precondition for developing coherent conscious experience [Safron, 2020]. According to IWMT, a coherent self-world model also requires organizing this information into spatiotemporal trajectories. However, IWMT highlights that these generative models cannot produce consciousness unless their outputs are functionally connected with each other and with its process [Safron, 2020]. Finally, IWMT suggests that the generation of subjective experience involves the process of a physical system (or its entailed mathematical object) calculating or probabilistically inferring the sequences of sensorimotor states and the models generating a particular combination of information present within and between sensory modalities [Safron, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="297" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n" style="vertical-align: 0.25em;"></mjx-mo><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c39"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-texatom space="2" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c5D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN" fence="true" stretchy="true" symmetric="true"></mo><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mn>2019</mn></mrow><mo>,</mo><mrow data-mjx-texclass="ORD"><mn>2020</mn></mrow></mrow><mo data-mjx-texclass="CLOSE">]</mo></mrow></math></mjx-assistive-mml></mjx-container> .</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="18" id="mark-f53ec02c-b504-4bcb-9535-21b840ae27f7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>IWMT provides several ideas which could be used toward building the features of the Conscious Aircraft. Similar to the Radical Plasticity Thesis, IWMT proposes the system's ability to exert cause and effect power over itself and to situate itself and contrast with others to gain experience from learning, thus highlighting that the Conscious Aircraft should learn about the environment and self, and the cause and consequence of actions toward the environment and self. Also, based on IWMT's suggestions on the self-world models and generative models, the world model can be seen as the digital twin of an aircraft, together with its environment. This provides the next requirement for an aircraft to have subjective experience, which is to generate a probabilistic digital twin of the aircraft, that can create counterfactual simulations (generate several views of the future) with respect to time (considering the past, present, and the future), space (considering different environments), and cause (considering a variety of causes and effects). This idea is also in line with "the hero of one's personal narrative with the ability of mental time-travel" version of self-consciousness mentioned in Sec. 2. Finally, IWMT's requirements that autonomy and selfhood being the preconditions of consciousness and generating subjective experience can be directly related to the Conscious Aircraft. Consequently, based on IWMT, for an aircraft to have conscious experience, it needs to be fully autonomous and self-aware.</div></div></div><div><br></div><h3><div><div>4.4. Default Space Theory</div></div></h3><div><br></div><div><div><div>The final theory under consideration is the Default Space Theory (DST) [Jerath et al., 2019]. DST proposes that the foundation of consciousness is a neural space replicating the three-dimensional space of the environment and other physical qualities, where sensory information is processed, integrated, and unified. While most theories propose that consciousness arises solely from the brain, DST claims that the default space is comprised of all cells of the body, connected by neurons and gap junctions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="298" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c64"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">d</mi></mrow></mrow></msup></math></mjx-assistive-mml></mjx-container> [Jerath and Beveridge,2018; Jerath et al.,2019].</div></div></div><div><br></div><div><div><div>DST posits that the processed signals (filtered, amplified, and integrated) in the brain return to the peripheral organs in a top-down-dominated fashion via lateral inhibition. <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="299" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c65"></mjx-c></mjx-mi></mjx-texatom></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">e</mi></mrow></mrow></msup></math></mjx-assistive-mml></mjx-container> This leads to the formation of expectations about reality,and incoming sensory information can simply "fall into place", allowing for a near real-time experience of the internal and external world [Jerath and Beveridge, 2018]. Hence, an experience of the external world is actually the internal representation of the external world generated by influencing memories, understandings of the physical world and expectations. By including the radical idea that sensory receptors are part of a component in the creation of a world simulation, DST provides insight into how this simulation is maintained and how it helps quick reaction to the external world [Jerath and Beveridge, 2018; Jerath et al., 2019].</div></div></div><div><br></div><hr><div><br><!-- Footnote --><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="300" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D451 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mi>d</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> Gap junctions are specialized intercellular connections between a multitude of animal cell types. They directly connect the cytoplasm of two cells, which allows various molecules, ions and electrical impulses to directly pass through a regulated gate between cells [Signorelli, 2017].</div></div></div><div><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="301" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-msup><mjx-texatom texclass="ORD"></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D452 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mrow data-mjx-texclass="ORD"></mrow><mrow data-mjx-texclass="ORD"><mi>e</mi></mrow></msup></math></mjx-assistive-mml></mjx-container> Lateral inhibition is the process by which stimulated neurons inhibit the activity of nearby neurons [Bakshi and Ghosh, 2017]. In lateral inhibition, nerve signals to neighboring neurons (positioned laterally to the excited neurons) are diminished. Lateral inhibition enables the brain to manage environmental input and avoid information overload. By dampening the action of some sensory input and enhancing the action of others, lateral inhibition helps to sharpen our sense of perception of sight, sound, touch, and smell [Bakshi and Ghosh, 2017]. The concept of lateral inhibition, when adapted to aircraft, has the potential of reducing information overload for pilots.</div></div></div><div><br><!-- Footnote --><br></div><hr><div><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="19" id="mark-bdd9adff-3bfc-405c-bfc7-82646bf1d3e6" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>Similar to IWMT, DST's suggestion on the world model being a 3D space representing the environment and other physical qualities where all the sensory information from every cell is processed, integrated, and unified, can be transpired to the Conscious Aircraft. Here, the digital twin of the Conscious Aircraft can be made up of sensor information from its components, subsystems, and systems, which can be integrated to provide the cellular as well as the overall picture of the aircraft's health.</div></div></div><div><br></div><h3><div><div>4.5. Summary and discussion</div></div></h3><div><br></div><div><div><div>Each of these cognitive neuroscience theories has different views on what constitutes a conscious experience and which parts of the brain, and the body are linked with consciousness. While the Radical Plasticity Thesis claims that a conscious experience is generated by the brain generating a theory about the environment, and about itself, the GWT claims that consciousness involves the brain implementing the global workspace. IWMT claims that conscious experience is generated via probabilistic world models emerging as Self-Organizing Harmonic Models made up of complexes of integrated information and the global workspaces. Learning occurs through continuous engagement with environments, generating coherent and precise inference, with preconditions of selfhood and autonomy. To complete the theories reviewed here, DST claims that conscious experience is generated by replicating the environment of a 3D space with sensory information from all parts of the body.</div></div></div><div><br></div><div><div><div>Notwithstanding the many different views and theories of consciousness, there are some significant outcomes from this section to inspire the concept of a Conscious Aircraft. Not all of the derived takeaways are independent of each other, and the selection of features would be made depending on the requirement of a given project. Also, the implementation of the identified takeaways for an aircraft would not mean that the aircraft could become conscious. The focus is rather on increasing the ability of the aircraft to mimic some features of human consciousness, with or without ongoing debate. The concepts of maximized integrated information in the systems, implementation of global workspace, digital twins representing world-models, learning about self and environment and emotional feedback are not entirely new, and there are some engineering applications already in existence. However, the extent to which these concepts are realized are insignificant when compared to the human capability. Besides, combining these concepts with the preconditions of autonomy and selfhood makes them increasingly complicated for the synthetic generation of both access and phenomenal consciousness for any system, including aircraft. Building on these key requirements to move toward a conscious experience, the following section discusses the significant developments and philosophies in the field of AI to identify the gaps and requirements for generating machine consciousness.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="20" id="mark-dd4fadf6-fffe-436f-95ce-c2a8c8a71845" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h2><div><div>5. Machine Consciousness</div></div></h2><div><br></div><div><div><div>The terms consciousness and intelligence are used interchangeably in many references since there are no clearly accepted definitions for them, and the relationship between them is not linear. For instance, Gamez [2020] claims consciousness to be a bubble of experience and links it to spatiotemporal patterns in specific physical materials, whereas intelligence is claimed as a purely functional property of a system. On the other hand, as seen in Sec. 2, Zeman [2001] proposes that the term consciousness can be seen in two perspectives: (i) inner perspective as experience, and (ii) outer perspective as intelligence. It can also be observed that it is not necessary for a conscious system to be fully intelligent, e.g., human baby [Li et al., 2021; Trevarthen and Reddy, 2007], or for an intelligent system to be fully conscious, e.g., plant intelligence [Trewavas, 2003], swarming in bees and flocking in birds; there is no correlation or dependent relationship between the two terms. However, in general, intelligence is understood in terms of solving problems in an efficient way through planning, reasoning, memory, and learning, while consciousness is understood in terms of subjective experience, emotions, ethics, and moral values. Notwithstanding this debate, in order to move toward practical implementations of what has been discussed so far, this section presents developments in the area of AI with respect to machine consciousness and showcases different theories and axioms which have influenced the world of machine consciousness.</div></div></div><div><br></div><h3><div><div>5.1. Progress in artificial intelligence and machine consciousness</div></div></h3><div><br></div><div><div><div>AI has developed massively since Turing questioned, through a thought experiment, whether or not a machine could think and converse like a human [Turing, 1950]. Figure 5 summarizes the timeline of AI development, both from a philosophical and a practical point of view. The Turing test has been used as a measure of AI, especially for machines developed to meet and surpass human intelligence. It also inspired a class of functionalism theories called Machine State theories which influenced the development of this doctrine in the 1960s [Levin, 2018]. The Turing test was criticized by John Searle, who claimed that machines could manipulate a situation to converse like a human and need not think for that purpose [Cole, 2020]. Searle proposed a thought experiment called the Chinese Room in 1980, through which he claims that with the help of the instructions, an operator, without prior knowledge in Chinese, is able to pass the Turing test, without having to understand the questions or the answers in Chinese language [Cole, 2020]. The argument is that a computer program (like Alexa/Siri/ChatGPT) cannot have a mind, or be conscious, despite its</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="21" id="mark-6a2800f2-9e5b-4b2f-b2d6-664841930c97" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br><!-- Media --><br><!-- figureText: Capability OpenAI's ChatGPT4 (2023) Loon (2020) - AI chatbot famous for detailed answers - AI autonomously across several implemented ancient domains the Stratospheric Balloons JEOPARDY! Go (2016) - AlphaGo Google Jeopardy DeepMind) beat (2011) Sedol Poetry (2020) IBM Watson - Generative Pre- beats two trained champions Transformer Human Brain (GTP)-3 Project, BRAIN Initiative (2013) Winograd Schema -Hector Levesque -Amazon, Google, Facebook, Apple To Identify the -IEEE Standards antecedent of an ambiguous pronoun in a statement 2023 Chess (1997) - Deep Blue Wabot-1 Expert (1974) systems Kasparov -World's first (1980s) Humanoid All Winter All Winter AI Milestones (1974-1980 Chinese Room Turing Test (1950) Searle AI Philosophy -Alan Turing 'Strong AI vs Weak AI' ’Can Machines think?’ "Strong AI vs Biological Naturalism (Consciousness) \( {}^{\prime } \) 1950 Time --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_20.jpg?x=337&amp;y=335&amp;w=797&amp;h=1786&amp;r=-1" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_20.jpg?x=337&amp;y=335&amp;w=797&amp;h=1786&amp;r=-1"><div><br></div><div><div><div>Fig. 5. Timeline of major developments in Artificial (Narrow) Intelligence.</div></div></div><div><br><!-- Media --><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="22" id="mark-303b46c3-2fd4-485e-892d-9f2a588440c7" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>intelligence in effectively communicating with humans and passing the Turing test. Searle claims that consciousness is possible only in biological mechanisms (neural correlates of consciousness) found in brains (biological naturalism, similar to identity theory) [Cole, 2020]. Since the Chinese room argument, the criteria to test the intelligence of artificial systems have become more sophisticated. One such challenge is the Winograd Schema [2012] which was developed to identify the antecedent of an ambiguous pronoun in a statement [Kocijan et al., 2020].</div></div></div><div><br></div><div><div><div>With further developments in the field of AI, two different types of AI were defined. Strong AI, referred to as Artificial General Intelligence, is defined as a machine having a mind. Here, the AI is seen as learning, reasoning, and performing any task on a par with a human [Dvorsky, 2013]. Weak AI, also referred to as Artificial Narrow Intelligence, is seen as a machine simulating a mind [Gamez, 2008], being programmed for certain goals.</div></div></div><div><br></div><div><div><div>Continuing to the practical side of Fig. 5, the very first Unimate, patented by George C. Devol, Grandfather of robotics in 1954, was later modified for industrial purposes to improve manufacturing efficiency in the 1960s by Joseph Engleberger, the father of robotics [Malone, 2011]. In addition, Shakey, a general-purpose robot, was developed by Stanford Research Institute around the same time [Perry, 2017]; it could move and interact with its environment to a certain extent. Since then robotics has come a long way, recently being used for conservation projects, e.g., Slothbot being used to monitor environmental interactions in the Atlanta botanical garden [Kann, 2020], and robots being used for navigation in complex spaces [Talbot et al., 2021], and grilling hot dogs [Linder, 2019; Li et al., 2019]. AI has also proven immense intelligence by beating champions in games like Chess, Jeopardy, and AlphaGo [Swiechowski, 2020]. Machine Learning algorithms are reported to have steered stratospheric balloons autonomously using old steering methods like tacking, despite not understanding about sailing [Baraniuk, 2021] and to have written poems (Generative Pre-trained Transformer (GPT)-3 [Anderson, 2021]). However, no AI currently has the social capabilities or emotions that are distinctively human. For example, Microsoft had to shut down their chatbot, Tay, because it sent inappropriate messages after interacting and learning from users on social media [Pens-worth, 2020]. Owing to such mishaps, there are initiatives to develop an ethical framework for AI systems, which are being proposed worldwide [Ad Hoc Expert Group (AHEG) for the Preparation of a Draft Text of a Recommendation on the Ethics of Artificial Intelligence, 2020; UN News, 2021]. The recent release of Open AI's ChatGPT-4, which was developed using transfer learning and reinforcement learning upon its previous versions [OpenAI, 2023], has proven to be more successful in generating content about several topics. This has led to the tool being used for authoring content or aiding research, and has made the use of ChatGPT contentious, especially concerning plagiarism as well as automating/replacing jobs. Alongside these projects, to further AI toward more generic human actions and consciousness, projects such as the Human Brain Project [Human Brain Project, 2017] and the Brain Initiative Project [The BRAIN Initiative, 2017] are focusing on developing and simulating brain models to understand the mechanisms of a brain. Meanwhile, competitions are proposed to encourage game development that mimics human behaviors aiming toward Artificial General Intelligence [Swiechowski, 2020].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="23" id="mark-04c0a981-fdd8-4ae4-a4c6-c6d4fd6cef03" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h3><div><div>5.2. Autonomous systems</div></div></h3><div><br></div><div><div><div>Autonomous systems are the current pinnacle of AI technology and are growing with the aim of transitioning from Artificial Narrow Intelligence to Artificial General Intelligence. According to IWMT (from Sec. 4), autonomy is a precondition for consciousness [Safron, 2020]. A complementary view, proposed by Sanz and Aguado [2020], claims that consciousness is required for an agent with autonomy to properly act by itself in a changing uncertain world. These two statements show the relationship between autonomy and consciousness: for a system to be conscious, it has to be autonomous to begin with, and for an autonomous system to reach its fullest capabilities, it needs to be conscious.</div></div></div><div><br></div><div><div><div>The development of an autonomous system involves the integration of different types of data from different subsystems, each with its individual goals, working together to develop a coherent picture in order to adapt to changes in its environment. Hence, autonomous systems also require selfhood capabilities like self-monitoring, and self-management, to adapt to the changes during operation [Chen et al., 2021]. While a majority of the development in autonomous systems is with military applications — e.g., F35 Lightning II and Manned-Unmanned Teaming for rotorcraft operations with airborne operator control of multiple UAVs [Taylor, 2018] - they are being widely implemented with various grades of autonomy for most civil and commercial applications. Examples include: automotives (e.g., self-driving cars), grocery delivery (e.g., Starship's robots delivering groceries in the US and European cities [Starship Technologies, 2022]) and the hospitality sector (disinfecting robots used in five-star hotels like Marriott and Hilton, and in Heathrow Airport and London St. Pancras Train Station [Shadel, 2021]).</div></div></div><div><br></div><div><div><div>The idea of autonomous systems is not limited to computers, vehicles or products in operation, but extends to the entire value chain, including maintenance and services. For example, a zero-maintenance philosophy has increasingly gained interest in the field of high value assets like aircraft and self-driving cars, where the maintenance requirements are assessed autonomously with support from self-healing (cause, detection, diagnosis, and corrective action) and self-repair processes to ensure the asset availability [Addepalli et al., 2017]. Similarly, the use of digital twins is also suggested for autonomous maintenance for aircraft systems, in order to emulate the real operation, diagnose faults, and generate and assess new scenarios, faults, and operating conditions [Khan et al., 2020]. However, most of the applications of autonomous systems are still in the conceptual phase, as the practical implementation depends upon the advancement of complementary fields, including sensor technologies, computational capabilities, AI techniques and AI Safety.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="24" id="mark-ab312477-193b-4a3a-b31f-c48854750305" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>At present, there are no fully autonomous systems, as they are still dependent on their human counterparts for many functions. Rather, the maturity of system autonomy involves step changes in their different processes and functions during implementation and operation. There are several taxonomies and frameworks established to gradually remove the involvement of humans in system operations. An example of such a taxonomy is SAE's IVHM system capability, developed for aircraft and automotive maintenance [HM-1 Integrated Vehicle Health Management Committee, 2018]. According to this taxonomy, as shown in Fig. 6, there are six levels of vehicle health capability, ranging from Level 0 (no autonomy) to Level 5 (self-adaptive health management system).</div></div></div><div><br></div><div><div><div>There are various human-machine integration challenges in delivering autonomous systems, such as the level of control shared between machines and humans, explainability and trustworthiness of the high-level decisions made by the autonomous system, and the legal perspectives of such decision-making process [Dennis and Fisher, 2020]. Thus, for an autonomous system to function in a human-centric world, it must address the technological barriers like cyber security threats, real-time information processing, and seamless trading and sharing controls with human operators. In addition, it has to adapt to evolving environmental changes, by possessing the self-x capabilities, be self-aware of its own thought process (what decisions are made and why?) and verify the legal and ethical nature of the decisions made. Since the autonomous system will be replacing human operators, it should also be able to explain its methods with transparency, particularly in the case of failures leading to damage, human injury or similar scenarios. Autonomous systems should understand the meaning and effect of their self-generated actions and can be made responsible by reacting to past actions by retrospectively computing values [Sanz et al., 2007; Sanz and Aguado, 2020]. In other words, autonomous systems need to be conscious to act properly in the uncertain world [Sanz and Aguado, 2020].</div></div></div><div><br><!-- Media --><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>SAE Level</td><td>Vehicle Health Capability</td><td>Narrative Description</td><td>Participation in Repair Actions</td><td>Key Data Resources</td><td>Availability of Logged &amp;/or Real-Time Data</td><td>Use of Supporting Models</td><td>IVHM System Characteristics</td></tr><tr><td colspan="8">Manual Diagnosis &amp; Repair Process performed by Technician</td></tr><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=198&amp;y=1341&amp;w=39&amp;h=54&amp;r=0"> </td><td>Limited On-Vehicle Warning Indicators</td><td>Service actions for scheduled maintenance or when Operator notices problems or is alerted by indicator lights or simple gages.</td><td>Operator/Driver &amp; Service Tech</td><td>On-Vehicle Measurements &amp; Observation</td><td>N/A</td><td>Paper-based Manuals</td><td>Only Manual Diagnostic Tools &amp; No Condition- Based Services</td></tr><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=198&amp;y=1451&amp;w=37&amp;h=59&amp;r=0"> </td><td>Enhanced Diagnostics Using Scan Tools</td><td>Service techs gain added diagnostic insight using automated scanners to extract vehicle operating parameters &amp; diagnostic codes.</td><td>Operator/Driver &amp; Service Tech</td><td>On-Vehicle &amp; Service Bay/ Depot Tools</td><td>Logged Diagnostic Codes &amp; Parameters available to Service Tech</td><td>Paper-based Manuals</td><td>On-Board Diagnostics Available</td></tr><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=195&amp;y=1555&amp;w=44&amp;h=58&amp;r=0"> </td><td>Telematics Providing Real-Time Data</td><td>Service techs gain real-time vehicle data via remote monitoring of vehicle to more completely capture issues.</td><td>Operator/Driver, Service Tech &amp; Remote Support Center Advisor</td><td>On-Vehicle, Service Bay / Depot &amp; Cloud Data</td><td>Telematic Data Available to Service Tech with Diagnostics Info</td><td>Paper-based Manuals</td><td>On-Board &amp; Remote Data Available</td></tr></tbody></table></div><br></div><div><div><div>Diagnosis &amp; Repair Augmented by Prognosis &amp; Predictive Analytics</div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=197&amp;y=1709&amp;w=41&amp;h=54&amp;r=0"> </td><td>Component Level Proactive Alerts</td><td>Operator and service techs are provided with component health status (R/Y/G) before problem occurs . Limited condition-based maintenance.</td><td>Operator/Driver, Service Tech &amp; Cloud-Based Services</td><td>On-Vehicle, Service Bay &amp; Cloud Data</td><td>Telematic Data Available to Service Tech with Diagnostics Info</td><td>Addition of Component- Level Health Models</td><td>Component-Level Health Predictions</td></tr><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=195&amp;y=1838&amp;w=45&amp;h=55&amp;r=0"> </td><td>Integrated Vehicle Health Mgmt.</td><td>Operator and service techs are provided with system or vehicle level health indicators before problems occur with remaining useful life estimated. Condition-based maintenance.</td><td>Operator/Driver, Service Tech &amp; Cloud-Based Services</td><td>On-Vehicle, Service Bay &amp; Cloud Data</td><td>Telematic Data Available to Service Tech with Diagnostics Info</td><td>Addition of Vehicle-Level Health Models</td><td>Vehicle-Level Health Management</td></tr><tr><td> <img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_23.jpg?x=198&amp;y=1969&amp;w=40&amp;h=53&amp;r=0"> </td><td>Self- Adaptive Health Mgmt.</td><td>Self-adaptive control and optimization to extend vehicle operation and enhance safety in presence of potential or actual failures.</td><td>Operator/Driver, Service Tech &amp; Cloud-Based Services</td><td>On-Vehicle, Service Bay &amp; Cloud Data</td><td>Telematic Data Available to Service Tech with Diagnostics Info</td><td>Addition of Vehicle-Level Health Models</td><td>IVHM Capability Integrated into Vehicle Controls</td></tr></tbody></table></div><br></div><div><div><div>Fig. 6. SAE's levels of IVHM capability for aerospace and automotive applications [HM-1 Integrated Vehicle Health Management Committee, 2018], reproduced with permission; copyright SAE 2018.</div></div></div><div><br><!-- Media --><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="25" id="mark-f7d3234a-9239-4164-99a4-4bebd24fbc76" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><h3><div><div>5.3. Theories of machine consciousness</div></div></h3><div><br></div><div><div><div>While Sec. 5.1 showcased the progression made in the fields of AI and machine consciousness, and Sec. 5.2 established the necessity for autonomous systems to evolve with features of consciousness and selfhood capabilities, this section presents four theories about the levels and types of machine consciousness. Figure 7 is an attempt to bring all these theories of machine consciousness together and compare their features with each other. Again, the outcome of this section will be used as a guideline in deriving the features required in the futuristic Conscious Aircraft.</div></div></div><div><br><!-- Media --><br><!-- figureText: Level 3: Level 11: Super Conscious: Level 10: Human Like: Adult human Level 9:Social: 4 year old human child Level 8: Empathetic: Chimpanzee Level 7: Self-Conscious: 18 month old baby Level 6: Emotional: Monkey Level 5: Executive: Quadruped mammal Level 4: Attentional: Fish Level 3: Adaptive: Earthworm Level 2: Reactive: Virus Level 1: Decontrolled: Dead bacteria Level -1: Disembodied: Amino acid of a protein ConsScale's levels of Consciousness ‘What-if’ imaginations Group Consciousness Emotion Level 2: Planning Social Self-Awareness Attention Imagination Self-Perception Level 1: Mobile Depiction Level 0: No/ Low mobility Aleksandar and Dunmall's Minimally Li et.al's Three Conscious levels of Kaku's Space- System Consciousness Time theory --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_24.jpg?x=174&amp;y=1065&amp;w=1201&amp;h=1007&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_24.jpg?x=174&amp;y=1065&amp;w=1201&amp;h=1007&amp;r=0"><div><br></div><div><div><div>Fig. 7. Theories relating to machine consciousness.</div></div></div><div><br><!-- Media --><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="26" id="mark-159af822-509c-4c54-89ce-1b3ed9d55319" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><h4><div><div>5.3.1. Axioms and tests for the presence of minimal consciousness in agents</div></div></h4><div><br></div><div><div><div>As seen in Fig. 7, Aleksander and Dunmall [2003] proposed five principles that are required for a system to be minimally conscious. The five features necessary for an agent to be minimally conscious of its environment are: (1) Depiction, (2) Imagination, (3) Attention, (4) Planning and (5) Emotion. According to Aleksander, a conscious machine must have the means to demonstrably depict and use the otherness (viewing oneself as separate by comparing with others) of the perceived world, to imagine alternative worlds and the effect of its actions [Aleksander, 2017]. These features can be compared with the requirement of a conscious system to develop a world model (as per IWMT and DST) that can carry out counterfactual simulations and have a mechanism for emotional feedback on its actions (as per Radical Plasticity Thesis).</div></div></div><div><br></div><h4><div><div>5.3.2. Three levels of consciousness</div></div></h4><div><br></div><div><div><div>The second theory presented is by Li et al. [2021] who claim three levels are required for consciousness: (1) Self-perception, (2) Self-awareness, and (3) Group Consciousness (seen in Fig. 7). They claim that for a system to be conscious, it has to first perceive a differentiation between self ("I") and others ("non-self"). Then it should recognize and be aware of itself, including its emotions and thoughts, and finally, it should be able to share its inner perspective with the outside environment, leading to forming culture and values. This concept has the same perspective of selfhood precondition as suggested by IWMT, as well as some commonality with the six perspectives of self-consciousness by Zeman, discussed in Sec. 2.</div></div></div><div><br></div><h4><div><div>5.3.3. Space-time theory of consciousness</div></div></h4><div><br></div><div><div><div>In contrast to the three levels of consciousness presented in Sec. 5.3.2, the Space-Time Theory of Consciousness (STC) proposes four levels of consciousness which start with assuming consciousness in plants [Kaku, 2014]. The different levels of STC can be seen in Fig. 7. According to this theory, Level 0 of consciousness represents organisms with low or zero mobility that create models of their space using feedback loops with few parameters. For example, plants which use parameters like sunlight, temperature, moisture, and gravity, create a model of their place using feedback loops and thus have Level 0 consciousness. Level 1 consciousness represents organisms like reptiles, which are mobile and have a central nervous system. The capability of movement requires more parameters (e.g., smell, sight, touch) as well as more feedback loops for generating models of the location of the organism and others (for example, prey). Level 2 consciousness represents social animals with emotions, such as mammalians. These organisms create models not only about their space but also their position with respect to others and use feedback loops that enable them to interact socially with the members in their groupings. Finally, Level 3 describes human consciousness as a specific form of consciousness that creates a model of the world and then simulates it in time, by evaluating the past to simulate the future. This requires mediating and evaluating many feedback loops in order to make a decision to achieve a goal [Kaku, 2014].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="27" id="mark-db498a21-9446-4389-831c-dcf1d0686215" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>Kaku's suggestion that consciousness is based on feedback loops is again similar to the world model proposed by IWMT and DST. The idea that social skills are required for reaching human-level consciousness also agrees with the Radical Plasticity Thesis which insists that learning about others is an important feature of consciousness. Kaku's STC emphasizes the relationship between cognitive neuroscience and theoretical physics (similar to Tegmark and Rovelli, as discussed in Sec. 3), by showcasing the progression in brain studies with the help of physics.</div></div></div><div><br></div><div><div><div>For every level of consciousness, Kaku introduces the degree of consciousness based on the number of feedback loops used by the organisms in order to create their required models. For example, at Level 0 consciousness where the subjects are immobile or with low mobility, a thermostat that can be switched on and off based on the temperature required will have a single unit of consciousness at Level 0, i.e., 0:1. At the same level, if a flower considers four parameters like temperature, gravity, moisture, and sunlight for its feedback loop, it could have a consciousness represented by 0:4 [Kaku, 2014].</div></div></div><div><br></div><h4><div><div>5.3.4. ConsScale levels of consciousness</div></div></h4><div><br></div><div><div><div>ConsScale [Arrabales et al., 2009] is another bio-inspired scale proposed to measure consciousness in artificial systems/agents, which can also be used as a roadmap toward machine consciousness. ConsScale defines 11 levels of incremental progression for agents as shown in Fig. 7 and Table 2, where the levels are compared with biological analogies ranging from a single-cell protein, virus, to monkeys, human babies, and human adults.</div></div></div><div><br></div><div><div><div>A ConsScale Quantitative Score (CQS) is proposed to measure the level of cognitive ability agents attain at each stage using the list of cognitive actions required to complete each level and move to the next. The CQS measure represents the cumulative synergy produced by adding and integrating cognitive features level after level. The CQS measure can be adapted based on different perspectives of the agent, such as perception and action, emotions, and Theory of Mind [Arrabales et al., 2009].</div></div></div><div><br></div><h4><div><div>5.3.5. Comparison and discussion</div></div></h4><div><br></div><div><div><div>The subsections in Sec. 5, discussing the key features, roadmaps, and types of machine consciousness, are not a complete list of proposals on machine consciousness. Similar to the reported debates in Secs. 2-4, there is no consensus among the AI community on whether or not machine consciousness is achievable. While the main purpose of the theories presented in this section is to provide the key features and stages required for consciousness, they can also serve as a measure of consciousness in AI systems. For example, in addition to measuring the level of cognitive ability of the agents, the CQS measure, based on ConsScale, can be used as a guideline for developing conscious machines. The same applies to Kaku's four levels of consciousness and the degree of consciousness. With respect to the STC, autonomous systems like self-driving car will correspond to Level 1 consciousness, since it needs to create models about its space, whereas intelligent agents with grouping and evolving capabilities belong to the early stages of Level 2 consciousness.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="28" id="mark-14017bcb-8310-4d1e-b00b-90feb8b8ae9d" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br></div><div><div><div>Table 2. ConsScale levels of consciousness [Arrabales et al., 2009].</div></div></div><div><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>Levels</td><td>Brief descriptions</td></tr><tr><td>Level 1 (Decontrolled)</td><td>Agents with sensors and actuators, no working relationship between them.</td></tr><tr><td>Level 2 (Reactive)</td><td>Sensory and actuating mechanisms of the agents related to pre-defined functions, providing fixed reactive responses.</td></tr><tr><td>Level 3 (Adaptive)</td><td>Agent's actions based on current information acquired by the sensors, along with memory, with the ability to learn new reflexes and the use of pro- prioceptive sensing for positioning and orientation behaviors.</td></tr><tr><td>Level 4 (Attentional)</td><td>The agent can select specific content from its repertory and evaluate them positively or negatively, thus forming the basics of emotions.</td></tr><tr><td>Level 5 (Executive)</td><td>The agent can choose multiple goals with different working sets from its memory, with possible preferences for tasks with the most rewarding emotions.</td></tr><tr><td>Level 6 (Emotional)</td><td>Equivalent to Theory of Mind's Stage 1 concept of "I know". The agent can generalize its learned lessons to its behavior, map out the emotions, assign emotions to self and self-status monitoring, thus leading to self-evaluation that gives a sense of "I know".</td></tr><tr><td>Level 7 (Self-conscious)</td><td>Equivalent to the Theory of Mind's Stage 2 concept, "I know, I know". The agent has the ability of self-recognition by generating a model of self and using its learning capability with anticipation of the future.</td></tr><tr><td>Level 8 (Empathetic)</td><td>Equivalent to Theory of Mind's Stage 3 concept of "I know, you know". Intersubjectivity is the key characteristic, where the agent has the model of the self as well as models of others as selves.</td></tr><tr><td>Level 9 (Social)</td><td>Equivalent to Theory of Mind's Stage 4, "I know, you know, I know". At this stage, the agent has social intelligence and is capable of developing culture.</td></tr><tr><td>Level 10 (Human-like)</td><td>The agents are capable of adult human-level technical and social intelligence, can form complex cultures, provide accurate verbal reports, and use external tools for learning.</td></tr><tr><td>Level 11 (Super- conscious)</td><td>The agents can streamline and coordinate several streams of consciousness in themselves.</td></tr></tbody></table></div><br><!-- Media --><br></div><div><div><div>Figure 7 aligns the levels of four theories applicable to machine consciousness (arranged horizontally and highlighted with same colors), in such a way that each of the principles/levels from one theory can be compared to another theory's levels. The right side of Fig. 7 has the ConsScale levels, against which, all the other theories are aligned. For example, the levels highlighted in purple color, represent no/low mobility. The green colored levels across all theories represent mobile beings with self-perception. Similarly, the pink colored levels denote the beings with capabilities ranging from emotions to empathy. Finally, the blue colored levels represent the capabilities of thinking "what-if" scenarios. In Li et al.'s theory, while the self-awareness stage is equivalent to emotion and self-consciousness stage of ConsScale (the pink colored levels), the empathy stage is possible only with the next level group consciousness. Hence, the next stage, the group consciousness level is aligned across these two levels, to cover the empathy stage as well as the "what-if" capabilities.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="29" id="mark-27170657-c545-492b-9775-ac833c1c6c1f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>In this perspective, it can be noticed that the ConsScale levels of consciousness provide a linear scale bridging the gap between the minimally conscious system suggested by Aleksandar et al. and the major levels of consciousness suggested by both Li et al. and Kaku. On the other hand, while Li et al.'s three levels of consciousness begin with the process of identifying the self and focus on differentiating others and the world, Kaku's levels of consciousness begin with any system that can generate a feedback loop as a beginning state of consciousness and provides a more granular level of progress. These stages from different theories are used as a guideline for developing the features of a Conscious Aircraft. It is suggested that the theory with the least number of levels (three levels of consciousness) can be adapted as the major stages of development of a Conscious Aircraft, and all the other theories can then be used to develop the features with more granularity within the proposed three stages.</div></div></div><div><br></div><h2><div><div>6. Journey Toward a Conscious Aircraft</div></div></h2><div><br></div><div><div><div>So far, this paper has glimpsed, through the fields of philosophy, cognitive neuroscience, and AI, an understanding of the features that contribute to consciousness. This section now builds on the outcomes from these different fields with IVHM as the enabling capability. From the aircraft maintenance, operations, and health management perspectives, the section approaches the journey to a Conscious Aircraft in three distinct stages: (i) Conscious Aircraft with system-awareness, (ii) Conscious Aircraft with self-awareness, and (iii) Conscious Aircraft with fleet-awareness. These three stages have been influenced by Li et al.'s three levels of consciousness.</div></div></div><div><br></div><div><div><div>Figure 8 shows three influencing factors: (1) Self-x capabilities (left side of Fig. 8), (2) Autonomy (right side of Fig. 8), and (3) Human-Machine Interaction (bottom section of Fig. 8) plotted against the different stages. Almost all theories discussed in this paper agree upon a conscious system requiring the sense of self. Selfhood (or self-x capabilities, in this case) is important in distinguishing oneself from the rest in the environment. This, combined with full autonomy, are the preconditions of consciousness according to IWMT and they form the major goals for autonomous systems. Also, the evolution of any machine will have an impact on its interacting environment, especially with its human counterparts; hence the third factor is chosen to be Human-Machine Interaction. The three stages laid out for the Conscious Aircraft development are very high-level. The granular details required for the transition between the three stages can be steered by ideas from ConsScale or STC. For example, each feature adding to the consciousness capability can be scored by measures like cognitive ability or degree of consciousness, depending upon the theories chosen.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="30" id="mark-92d55613-4609-42f2-9754-4a8c7c28e68c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: Stage 3: Fleet Awareness Autonomous Digital Twin comparison counterfactual of fleet with simulations lessons for learnt for predictions future Health and meaning maintenance Management generation actions and sustainment tools to assist Autonomous Digital Twins decision maintenance generating request imaginative scenarios optimization based on current using fleet Maintenance health status lessons for future assisted by predictions some automated Autonomous actions maintenance action plans Autonomous and (few) decision-making, actions scheduling and co-ordination of maintenance logistics, and sustainment Recommendation to operators on the analysis and actions decision-making process (explainability and Transparent communication with humans on analysis and Stage 2: Self Awareness Self- conscious Self-Analysis Stage 1: System Awareness Fleet Self-Repair Awareness Self- Awareness Self-Monitoring Fleet-level Self- Self-Detection learning Adaptive The Self- Conscious diagnosis Aircraft Self- Self- assessment Knowledge on suitable Theory of levels of mind: Human- Machine learning from Theory of Stage 1: fleet mind: "I know" Interaction Stage 2: "I know I Theory of know" Report analysis to human operators for decision-making mind: Stage 3:“I know you know" trustworthiness). decision-making process, explaining the legal, ethical nature and intentions with possible human intervention --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_29.jpg?x=180&amp;y=299&amp;w=1199&amp;h=1091&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_29.jpg?x=180&amp;y=299&amp;w=1199&amp;h=1091&amp;r=0"><div><br></div><div><div><div>Fig. 8. Toward a Conscious Aircraft.</div></div></div><div><br><!-- Media --><br></div><h3><div><div>6.1. Stage 1: Conscious Aircraft with system-awareness</div></div></h3><div><br></div><div><div><div>This stage, considered the base for developing a Conscious Aircraft, is the representation of advanced aircraft in existence and forms the inner ring of Fig. 8. The health management systems at this stage correspond to an SAE Level 4 of IVHM capability [HM-1 Integrated Vehicle Health Management Committee, 2018], where several systems are deployed to monitor the health of the aircraft at the component and vehicle level. These systems provide the health indicators, including failure predictions, to the maintenance and support personnel for condition-based and predictive maintenance. Many state-of-the-art aircraft like the Lockheed Martin F35 Lighting Joint Strike Fighter (JSF) have advanced Prognostics Health Management (PHM) systems. These PHM systems can perceive and process the sensor data onboard and generate information that can be used by pilots, maintainers, fleet managers and other stakeholders [Kappas and Frith, 2017]. They have self-monitoring, self-detection, and self-diagnostic capabilities, thus being aware of the system during its operation. They are also engineered with sustainment tools to increase aircraft efficiency and cost effectiveness [Lockheed Martin, 2019]. In JSF, the Autonomic Logistics Information System (ALIS) processes all the information and provides decision making support for maintenance optimization [Kappas and Frith, 2017; Scott et al., 2022]. Also, ALIS can integrate a wider range of capabilities like operations, maintenance, prognostics, supply chain, customer support, training, and technical data, to provide up-to-date information required for the reduction of operations and maintenance costs and increase the availability of the aircraft [Lockheed Martin, 2019]. These abilities contribute to the automation and optimization of maintenance actions by providing analysis reports to human operators. Assisted by these analyses, the human operators including pilots and maintainers are able to take necessary actions when required. Comparing with the four stages of the Theory of Mind, the system awareness stage is equivalent to Level 1 "I Know", in which the system reacts to stimuli perceived, but the idea of self is not necessary [Lewis, 2003].</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="31" id="mark-c03df8b3-ccf9-4b01-afbd-1ea7c8e372c5" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h3><div><div>6.2. Stage 2: Conscious Aircraft with self-awareness</div></div></h3><div><br></div><div><div><div>The second stage toward the Conscious Aircraft, as shown in the middle ring of Fig. 8, is self-awareness. From the theories discussed in this paper, it is evident that the idea of self is important to distinguish between the self and the environment. The system with self-awareness will have knowledge about itself and will have the capability to learn about itself and the environment. According to Sanz and Aguado [2020], a system with self-awareness/consciousness generates meaning from continuously updated self-models. Thus, for generating meaning, the Conscious Aircraft should possess self-knowledge and knowledge about the environment by learning about itself through representational redescription, as per the Radical Plasticity Thesis. This will be possible by developing a digital twin of the aircraft that can continuously update itself based on the real time onboard and ground information about the aircraft and its environment, as shown in Fig. 9.</div></div></div><div><br></div><div><div><div>Figure 9 shows the conceptual working of a Conscious Aircraft, inspired by the Sense Acquire-Transfer-Analyze-Act (SATAA) cycle followed in IVHM. The bottom layer consists of the Conscious Aircraft in operation, sensing real-time onboard data about itself (present self-model) and the environment (world-model), and passing them to the next stages for meaning generation. The middle layer consists of the self-model of the Conscious Aircraft, consisting of the aircraft's digital twin with its latest representation along with its historical information, which is acquired and passed on to the next stages of meaning generation, together with present information from the bottom layer. The top layer shows the meta-model of the Conscious Aircraft, which uses the information from self-model of both present and past, along with the world-model, to continuously update itself, thus generating meaning. This level is equivalent to the Theory of Mind's Level 2 "I know I know" which represents the capacity of reflecting on oneself and what one knows [Lewis, 2003]. Thus, in the meta-model layer, by learning about itself, the Conscious Aircraft should also be able to autonomously carry out counterfactual simulations (what-if scenarios) about the future using its self-models, given its past and present scenarios (the hero of one's personal narrative, with the capability of mental time travel). Streamlining the results of counterfactual simulations, the Conscious Aircraft will then predict or prescribe the correct course of action with the help of its digital twin and adapt or reconfigure the mission based on its evolving environment in the real-time, as seen in Fig. 9. Thus, the Conscious Aircraft with self-awareness will be able to optimize its life and enhance safety in the presence of failures, satisfying SAE IVHM capability Level 5 in Fig 6, self-adaptive health management. Depending upon its current health status, the Conscious Aircraft at this stage will also have the ability to request maintenance, should it deem necessary. As seen in Fig. 9, from the ground-based operations perspective, the ecosystem surrounding the Conscious Aircraft should autonomously recommend upgrades and deep maintenance when needed, along with coordinating logistics like spare parts and demand management, and personnel required or available for maintenance. This resonates with the initial idea of the Conscious Aircraft (as presented in Sec. 1.1), where the aircraft is aware of its own health and takes necessary action to schedule maintenance, like patients consulting doctors. The Conscious Aircraft at this stage should process data not only from operations but include the entire ecosystem involving maintenance, and lifecycle services and support, thus optimizing the life and availability of the aircraft, considering trade-offs such as cost and design limits. This will also contribute to correctly representing the current scenarios and the prediction of the next course of action, utilizing digital twins. Such data-processing requirements for the onboard and ground operations of the Conscious Aircraft can be facilitated by a continuously woven digital thread of information from the entire ecosystem, ensuring continuity across the different stages of the aircraft lifecycle. This has potential benefits for monitoring the aircraft's environmental footprint throughout its life cycle in order to be compliant with circular economy.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="32" id="mark-af84fb61-a5bc-47c2-b0a7-5ebcc2912137" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: Theory of Mind: 'I know I know' Self-Analysis Counterfactual Simulations Self Self-diagnose Self-repair Autonomy Analyze Self- knowledge Optimize life and Predict/ availability Prescribe Schedule maintenance Co-ordinate logistics Human- Machine Act Interaction Mission Adapt/ Reconfigure Ground Operations Maintenance Personnel World knowledge + Self-Learning Self- knowledge (Past & Present) Meta-model Transfer Digital Twin Acquire Self-knowledge (Past) Self-model (Digital Twin) Conscious Aircraft with Self awareness Sense Self-knowledge World (Present) knowledge Environment Digital Thread Ecosystem Ground operations, Maintenance, Repair and Overhaul services --><br></div><img src="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_31.jpg?x=250&amp;y=305&amp;w=1055&amp;h=1009&amp;r=0" alt="https://cdn.noedgeai.com/019610a3-7a3c-71ba-a8c8-39162d87379c_31.jpg?x=250&amp;y=305&amp;w=1055&amp;h=1009&amp;r=0"><div><br></div><div><div><div>Fig. 9. Conscious Aircraft with self-awareness.</div></div></div><div><br><!-- Media --><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="33" id="mark-0170c493-9aae-4c88-9032-3f969b23ac56" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>At present, many unmanned aircraft prototypes are being flown with self-awareness capabilities such as autonomous collision avoidance, autonomous stall prevention, and dynamic mission re-planning based on in-flight structural damage, with the help of advanced sensors and the development of near real-time digital twins [Gregory, 2016; Allaire et al., 2013; Ham, 2021]. These prototypes are focused on one particular mission objective and constrained to limited sensory inputs. Building upon this progress, the Conscious Aircraft will have to consider various mission objectives with holistic view of all its components and their interactions. For "there are no properties outside of interactions" (according to the Nobel prize laureate Niel Bohr [Rovelli, 2022b]), the Conscious Aircraft with self-awareness will not only be aware of its individual systems and components, but it would also consider the interactions between the components at the systems level, and the interactions between the systems at the vehicle level, for predicting its course and future actions. The Conscious Aircraft with self-awareness will require the integration of multiple individual system health perspectives to develop holistic views. It can self-diagnose, and self-repair in the presence of faults at components/systems levels, leading to zero maintenance and can provide the prognosis of its life, thus contributing to predictive maintenance.</div></div></div><div><br></div><div><div><div>Figures 8 and 9 also emphasize on the Human-Machine Interaction of the Conscious Aircraft. The automated analysis and decision-making capabilities of the Conscious Aircraft should be transparent and easily explainable, for the human counterparts to understand at any stage of the process. Hence, it should communicate seamlessly with its human operators, essentially taking care of itself without depending on much human involvement. For large passenger aircraft, it is likely they will have a pilot/operator onboard at this stage, it is, therefore, essential that the interface between the human and the Conscious Aircraft is "seamless" and facilitates effective and timely decision making, with the continued presence of a pilot/operator as a final arbiter for flight critical decisions. This is also required for ground-based maintenance engineers who will continue to be responsible for the airworthiness of the aircraft. This "seamless" communication can be facilitated by the development of technologies like Human-Machine Interfaces. A key benefit of self-aware aircraft will be their ability to share that awareness with pilots/operators/engineers. In turn, this will allow for faster and better decisions when unexpected events occur during flights and reduce the risk of accidents caused by human error.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="34" id="mark-d0e30836-b8c3-483d-b041-e0d7d4466597" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>The collective intelligence due to the effective interaction between the Conscious Aircraft and human operators can be evaluated by IIT's integrated information value, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="302" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c3A6"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Φ</mi></math></mjx-assistive-mml></mjx-container> . The self-awareness capability of this Conscious Aircraft will be able to provide clarifications on the decision-making process, thus contributing to explainability, trustworthiness, safety and legal and ethical implications. Wherever contextual reasoning is required for better decision-making, the mechanism of the global workspace (from GWT) with conscious and unconscious modules could be used for establishing additional goals and constraints. The emotions and thoughts required for self-awareness can be equated to adaptive learning based on feedback and explainability. In this sense, the aircraft can be considered minimally conscious as per Aleksandar and Dunmall's axioms. Also, from the key features of the Radical Plasticity Thesis, the Conscious Aircraft would have emotional feedback and self-learning capabilities for its autonomy. This stage meets the main goal of autonomous systems, which is to gain full autonomy with self-x and transparent decision-making capabilities.</div></div></div><div><br></div><h3><div><div>6.3. Stage 3: Conscious Aircraft with fleet-awareness</div></div></h3><div><br></div><div><div><div>While most of the principles and goals for autonomous systems focus on achieving self-awareness, this paper identifies an additional goal for the Conscious Aircraft: fleet-awareness. The Radical Plasticity Thesis insists that a conscious system needs to learn about the self, the environment, as well as from others' behaviors. Similarly, IWMT also suggests that the conscious system shall situate itself and contrast with others to learn and gain experience. Grounded on these significant features, the Conscious Aircraft with self-awareness shall evolve to have fleet awareness in this third stage. Here, the Conscious Aircraft will be equivalent to the Theory of Mind's Level 3, "I know, you know", where one is aware that others know something as well, thus resulting in shared meaning.</div></div></div><div><br></div><div><div><div>The Conscious Aircraft with fleet awareness shall be able to compare its health scenarios with that of its fleet and learn from others' performance and maintenance actions, eventually this may extend to whole aviation ecosystem (e.g., the four As: Aircraft, Airline, Airspace and Airport). This learning can involve good lessons, e.g., that aircraft <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="303" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-n"><mjx-c class="mjx-c58"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi mathvariant="normal">X</mi></mrow></math></mjx-assistive-mml></mjx-container> with a health symptom in a system was scheduled for maintenance at a particular time and hence prevented a failure at its onset; X's fleet then learns that this can be done for them when such a symptom rises in their systems. It can also involve cautionary lessons, e.g., that aircraft Y's particular system failed due to missing a health symptom and hence the rest of the fleet need to watch out for that symptom. At this stage, the fleet of Conscious Aircraft will have a rich social environment to continuously learn about itself and other aircraft. The digital twin of the aircraft should generate different scenarios of the future based on imaginative pasts learnt from other aircraft, facilitated by the digital twin of the fleet. Similar to Stage 2, the collective intelligence of the fleet can be evaluated by IIT's integrated information value, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="304" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-n"><mjx-c class="mjx-c3A6"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi mathvariant="normal">Φ</mi></math></mjx-assistive-mml></mjx-container> ,and all the theories applied in Stage 2 for the individual aircraft are applicable to the fleet as well.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="35" id="mark-10cba0c2-5d90-4d57-8da4-651e0dd73b1c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>The fleet level trend analysis is common in maintenance practices; there are state-of-the-art swarm drones that can perform coordinated actions. However, most of the fleet-level actions are carried out by human operators, except for few tasks like fleet level scheduling of service event and trip [Mansouri et al., 2010]. The Conscious Aircraft with fleet awareness shall be able to learn from its fleet on its own and create a shared understanding that can lead to autonomous prescriptive maintenance. From the perspective of the entire ecosystem of the Conscious Aircraft, the ground operations required for maintenance and sustainment of the aircraft fleet should autonomously reason through the priority of the aircraft requiring maintenance given the resources available, to ensure continued airworthiness and availability, even if they are away from the base. Autonomous maintenance will also optimize the logistics footprint and coordinate to reduce the exposure of aircraft being repaired, which can also be enabled by self-healing/self-repair abilities of the individual aircraft. The digital thread developed for each aircraft throughout its lifecycle will help the Conscious Aircraft to consider the different learning levels of its fleet to understand the impact of the lessons learnt. The fleet should be able to communicate with its human counterparts (who will get involved only in supervising/authorizing the automated decisions) in a way that they can understand the analysis and process, especially the safety, legal, ethical nature and intentions of their actions. The interaction with human counterparts can be from both onboard and ground perspectives, and assuming that full autonomy without human intervention is possible throughout the ecosystem of the Conscious Aircraft. The Conscious Aircraft with fleet-awareness will propel the aviation industry to a more aware, autonomous, connected, and conscious future that fully meets the requirements of the circular economy.</div></div></div><div><br></div><h2><div><div>7. Summary and Conclusion</div></div></h2><div><br></div><div><div><div>This paper has attempted to envision the future of an aircraft from the perspective of consciousness. For this purpose, the paper looked at the concept of consciousness from various fields, and has derived that consciousness has no agreed-upon definition. Consciousness is identified, debated, and documented by humans because they can communicate their experiences. Even then, the experience of the same event by two different persons might be different either because of the way they perceive it or the way they communicate their experience. With this limitation, the answer to the question in point, "what would it be for an aircraft to be conscious?", could only be a projection from a human perspective. A Conscious Aircraft, if compared to a human, could feel highs and lows, experience emotions, could even choose to tell lies, have bias, or have a righteous will of its own and intentions about its working along with humans. Consciousness could even be equated to mindfulness (one of the three major contexts of consciousness), making the Conscious Aircraft, health-conscious, performance-conscious, and sustainability-conscious, similar to a human. On the other hand, an aircraft with consciousness could experience something entirely different and incomprehensible to a human. In either perspective, the discussions are not fruitful, for there is no way of knowing if the assumptions about a machine (be it a robot or an aircraft) gaining consciousness (subjective experience), and communicating the same with humans, are valid or not, until the occurrence of such events. Hence, this paper takes the biomimicry approach to the concept of the Conscious Aircraft by considering the significant takeaways from various views on consciousness, its emergence and functions, derived from the perspectives of: philosophy, cognitive neuroscience and AI.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="36" id="mark-5636eff5-8544-49d9-bb4c-9feeca4e00f0" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>The major outcomes from these theories bring out some common factors underlining the requirements for a conscious experience to occur; these are:</div></div></div><div><br><ul><li>Conscious experience involves learning about the self, environment, and others, including the cause and consequences of actions.</li></ul><br><ul><li>Conscious experience requires the system to have a model of itself and its world (digital twin), which should be updated continuously and carry out simulations to predict possible futures based on its past experience and current scenarios.</li></ul><br><ul><li>Autonomy and selfhood are preconditions for a conscious experience.</li></ul><br><ul><li>Conscious experience requires emotion to be part of its learning; the system needs to care about its experience to learn value from them.</li></ul><br></div><div><div><div>These factors, along with some specific theory takeaways (e.g., Table 1 from cognitive neuroscience and Fig. 7 from machine consciousness), enable conceptualization of a Conscious Aircraft through three stages (Fig. 8): (1) System-awareness, (2) Self-awareness (Fig. 9), and (3) Fleet-awareness. While most of the principles and frameworks guiding autonomous systems focus on self-aware, self-adaptive capabilities, this paper has identified that any conscious system (in this case, the Conscious Aircraft) needs to learn from others, i.e., from its fleet, as well. With that consideration, the different stages toward a Conscious Aircraft are presented in terms of its most influencing factors: selfhood, autonomy, and human-machine interaction. The technological, cybersecurity and other challenges are not considered in this concept. Rather, the goal has been to spring some inspiration from one of the most challenging debates of natural phenomena, to aid a paradigm shift in conceptualizing futuristic aircraft.</div></div></div><div><br></div><h2><div><div>Acknowledgments</div></div></h2><div><br></div><div><div><div>The authors would like to thank the Boeing Company for funding this work and for their interest in its outcome. In the nature of work like this many people, including colleagues and friends, have freely shared their experiences and input; the authors would just like to say thank you to all of them. Special thanks go to Kirby Keller (ex-Boeing) for his insights into fleet aspects of the Conscious Aircraft.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="37" id="mark-12d06c57-9c21-4a74-9784-3c0557c3ffb9" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h2><div><div>ORCID</div></div></h2><div><br></div><div><div><div>Cordelia Mattuvarkuzhali Ezhilarasu © https://orcid.org/0000-0003-2413-5033 Jim Angus | https://orcid.org/0000-0002-4892-665X</div></div></div><div><br></div><div><div><div>Ian K. Jennions &amp; https://orcid.org/0000-0002-5752-1873</div></div></div><div><br></div><h2><div><div>References</div></div></h2><div><br></div><div><div><div>Ad Hoc Expert Group (AHEG) for the Preparation of a Draft Text of a Recommendation on the Ethics of Artificial Intelligence [2020] First draft of the recommendation on the ethics of artificial intelligence, UNESDOC Digital Library, https://unesdoc.unesco.org/ark:/48223/ pf0000373434.</div></div></div><div><br></div><div><div><div>Addepalli, S., Zhao, Y. and Tinsley, L. [2017] Thermographic NDT for through-life inspection of high value components, in Advances in Through-life Engineering Services, Decision Engineering (Springer, Berlin), pp. 189-197, http://link.springer.com/10.1007/978-3-319- 49938-3.</div></div></div><div><br></div><div><div><div>Airbus [2019] Fello'fly, https://www.airbus.com/en/innovation/disruptive-concepts/biomi-micry/fellofly.</div></div></div><div><br></div><div><div><div>Albantakis, L. [2020] Integrated information theory, in Beyond Neural Correlates of Consciousness (Routledge), pp. 87-103, https://doi.org/10.4324/9781315205267-6.</div></div></div><div><br></div><div><div><div>Aleksander, I. and Dunmall, B. [2003] Axioms and tests for the presence of minimal consciousness in agents, J. Conscious. Stud.</div></div></div><div><br></div><div><div><div>Allaire, D., Chambers, J., Cowlagi, R., Kordonowy, D., Lecerf, M., Mainini, L., Ulker, F. and Willcox, K. [2013] An offline/online DDDAS capability for self-aware aerospace vehicles, Proc. Comput. Sci. 18, 1959-1968, https://doi.org/10.1016/j.procs.2013.05.365.</div></div></div><div><br></div><div><div><div>Anderson, D. [2021] When AI writes poetry, https://humanise.ai/blog/ai-writes-poetry/.</div></div></div><div><br></div><div><div><div>Angus, J. and Maggiore, J. [2022] Planning for a digital future, Aircraft IT MRO, https:// www.aircraftit.com/articles/planning-for-a-digital-future/.</div></div></div><div><br></div><div><div><div>Arrabales, R., Ledezma, A. and Sanchis, A. [2009] Establishing a roadmap and metrics for conscious machines development, in Proc. 2009 8th IEEE Int. Conf. Cognitive Informatics, ICCI 2009, pp. 94-101, https://doi.org/10.1109/COGINF.2009.5250795.</div></div></div><div><br></div><div><div><div>Baars, B. J. and Franklin, S. [2003] How conscious experience and working memory interact, Trends Cogn. Sci. 7(4), 166-172, https://doi.org/10.1016/S1364-6613(03)00056-1.</div></div></div><div><br></div><div><div><div>Bakshi, A. and Ghosh, K. [2017] A neural model of attention and feedback for computing perceived brightness in vision, in P. Samui, S. Sekhar &amp; V. E. Balas (eds.), Handbook of Neural Computation (Academic Press), pp. 487-513, https://doi.org/https://doi.org/ 10.1016/B978-0-12-811318-9.00026-0.</div></div></div><div><br></div><div><div><div>Baraniuk, C. [2021] How Google's balloons surprised their creator, BBC Future Machine Minds, https://www.bbc.com/future/article/20210222-how-googles-hot-air-balloon-surprised-its-creators.</div></div></div><div><br></div><div><div><div>Block, N. [2006] Consciousness, philosophical issues about, in Encyclopedia of Cognitive Science, https://doi.org/10.1002/0470018860.s00145.</div></div></div><div><br></div><div><div><div>Calef, S. [2021] Dualism and mind, Internet Encyclopedia of Philosophy, https://iep.utm.edu/ dualism-and-mind/.</div></div></div><div><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="38" id="mark-1071905c-8fc6-4e72-b470-8ac15166a078" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>Chalmers, D. [2017] The hard problem of consciousness, in The Blackwell Companion to Consciousness (John Wiley &amp; Sons), pp. 32-42, https://doi.org/https://doi.org/10.1002/ 9781119132363.ch3.</div></div></div><div><br></div><div><div><div>Chen, H., Wen, Y., Zhu, M., Huang, Y., Xiao, C., Wei, T. and Hahn, A. [2021] From automation system to autonomous system: An architecture perspective." J. Mar. Sci. Eng. 9(6), 645, https://doi.org/10.3390/jmse9060645.</div></div></div><div><br></div><div><div><div>Cleeremans, A. [2011] The radical plasticity thesis: How the brain learns to be conscious, Front. Psychol. 2(May), 1-12, https://doi.org/10.3389/fpsyg.2011.00086.</div></div></div><div><br></div><div><div><div>Cole, D. [2020] The Chinese room argument, Stanford Encyclopedia of Philosophy, https:// plato.stanford.edu/archives/win2020/entries/chinese-room.</div></div></div><div><br></div><div><div><div>Coventry, A. and Kriegel, U. [2008] Locke on consciousness, Hist. Philos. Q. 25(3), 221-242, http://www.jstor.org/stable/27745128.</div></div></div><div><br></div><div><div><div>Chalmers, D. J. [1996] Conscious Mind (Oxford University Press).</div></div></div><div><br></div><div><div><div>Chalmers, D. J. [2011] A computational foundation for the study of cognition, J. Cogn. Sci. 12(4), 325-359, https://doi.org/10.17791/jcs.2011.12.4.325.</div></div></div><div><br></div><div><div><div>Dennis, L. A. and Fisher, M. [2020] Verifiable self-aware agent-based autonomous systems, Proc. IEEE 108(7), 1011-1026, https://doi.org/10.1109/JPROC.2020.2991262.</div></div></div><div><br></div><div><div><div>Derriso, M. M., McCurry, C. D. and Desimio, M. P. [2012] Global workspace theory inspired architecture for autonomous structural health monitoring, in 2012 IEEE National Aerospace and Electronics Conf. (NAECON), pp. 190-195, https://doi.org/10.1109/NAE-CON.2012.6531054.</div></div></div><div><br></div><div><div><div>Dvorsky, G. [2013] How much longer before our first AI catastrophe? Gizmodo, https:// gizmodo.com/how-much-longer-before-our-first-ai-catastrophe-464043243.</div></div></div><div><br></div><div><div><div>Ezhilarasu, C. M. and Jennions, I. K. [2021] Development and implementation of a Framework for Aerospace Vehicle Reasoning (FAVER), IEEE Access 9, 108028-108048, https://doi.org/10.1109/ACCESS.2021.3100865.</div></div></div><div><br></div><div><div><div>Gamez, D. [2008] Progress in machine consciousness, Conscious. Cogn. 17(3), 887-910, https://doi.org/10.1016/j.concog.2007.04.005.</div></div></div><div><br></div><div><div><div>Gamez, D. [2020] The relationships between intelligence and consciousness in natural and artificial systems, J. Artif. Intell. Conscious. 7(1), 51-62, https://doi.org/10.1142/ s2705078520300017.</div></div></div><div><br></div><div><div><div>Goff, P., Seager, W. and Allen-Hermanson, S. [2022] Panpsychism, The Stanford Encyclopedia of Philosophy. https://plato.stanford.edu/archives/sum2022/entries/panpsychism/.</div></div></div><div><br></div><div><div><div>Gregory, I. M. [2016] Self-aware vehicles: Mission and performance adaptation to system health degradation, in 16th AIAA Aviation Technology, Integration, and Operations Conf. (American Institute of Aeronautics and Astronautics, Reston, Virginia), pp. 1-7, https:// doi.org/10.2514/6.2016-3165.</div></div></div><div><br></div><div><div><div>Guyer, P. and Horstmann, R.-P. [2021] Idealism, The Stanford Encyclopedia of Philosophy, https://plato.stanford.edu/archives/spr2022/entries/idealism.</div></div></div><div><br></div><div><div><div>Ham, B. [2021] Creating 'digital twins' at scale, MIT News, https://news.mit.edu/2021/ creating-digital-twins-scale-0614.</div></div></div><div><br></div><div><div><div>Hanley, W. S. [2002] Culture and Consciousness: Literature Regained (Bucknell University Press).</div></div></div><div><br></div><div><div><div>HM-1 Integrated Vehicle Health Management Committee [2018] SAE JA6268: Design &amp; run-time information exchange for health-ready components, SAE International, https:// saemobilus.sae.org/content/ja6268_201804.</div></div></div><div><br></div><div><div><div>Human Brain Project [2017] Short overview of the human brain project, https://www.humanbrainproject.eu/en/about/overview/.</div></div></div><div><br></div><div><div><div>Jennions, I. and Angus, J. [2022a] The rise of the conscious aircraft, The Engineer, https:// www.theengineer.co.uk/content/opinion/the-rise-of-the-conscious-aircraft.</div></div></div><div><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="39" id="mark-59ed67dd-f904-4e2c-b334-b1f9c515e133" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><div><div>Jennions, I. and Angus, J. [2022b] Why the next generation of aircraft need to become con-</div></div></div><div><br></div><div><div><div>scious, Aerospace Testing International, https://www.aerospacetestinginternational.com/ opinion/why-the-next-generation-of-aircraft-need-to-become-conscious-machines.html.</div></div></div><div><br></div><div><div><div>Jennions, I. and Angus, J. [2022c] Opinion: Are aircraft going to become 'conscious'? Aviation Week, https://aviationweek.com/mro/emerging-technologies/opinion-are-aircraft-going-become-conscious.</div></div></div><div><br></div><div><div><div>Jennions, I. K. [2021] Introduction to conscious aircraft, YouTube, https://www.youtube.com/watch?v=MZ_c3YXTmcM.</div></div></div><div><br></div><div><div><div>Jennions, I., Mason, K., Angus, J., Budd, T., Al-Rubaye, S. and Panagiotakopoulos, D. [2022] Digital now: Why the future of aviation starts with connectivity, Inmarsat Insights, pp. 21-24, https://www.inmarsat.com/en/insights/aviation/2022/future-aviation-connectivity.html#: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="305" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c223C"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∼</mo></math></mjx-assistive-mml></mjx-container> :text=Entitled Digital Now%3A Why the,has caused aviation's "key industry.</div></div></div><div><br></div><div><div><div>Jerath, R. and Beveridge, C. [2018] Critique and comparison of prevailing consciousness models with a novel embodied cognition model, World J. Neurosci. 8(3), 370-401, https:// doi.org/10.4236/wjns.2018.83030.</div></div></div><div><br></div><div><div><div>Jerath, R., Beveridge, C. and Jensen, M. [2019] The default space theory of consciousness: Phenomenological support from personal observations and clinical deficits, World J. Neurosci. 9(1), 1-21, https://doi.org/10.4236/wjns.2019.91001.</div></div></div><div><br></div><div><div><div>Kaku, M. [2014] The Future of the Mind: The Scientific Quest to Understand, Enhance and Empower the Mind (Penguin Books).</div></div></div><div><br></div><div><div><div>Kann, D. [2020] Meet the 'SlothBot,' the robot taking its sweet time to monitor our climate, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="306" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D436 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D441 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>C</mi><mi>N</mi><mi>N</mi></mrow></math></mjx-assistive-mml></mjx-container> , https://edition.cnn.com/2020/08/19/weather/slothbot-climate-monitoring-project-planet/index.html.</div></div></div><div><br></div><div><div><div>Kappas, J. and Frith, P. [2017] From HUMS to PHM: Are we there yet? in Tenth DST Group Int. Conf. Health and Usage Monitoring Systems, 17th Australian Aerospace Congress, Melbourne, https://humsconference.com.au/Papers2017/Not_on_USB_Proceedings/ 191_HUMS2017_Kappas.pdf.</div></div></div><div><br></div><div><div><div>Kastrup, B. [2019]. Analytic Idealism: A Consciousness-only Ontology.</div></div></div><div><br></div><div><div><div>Keromnes, G. et al. [2019] Exploring self-consciousness from self- and other-image recognition in the mirror: Concepts and evaluation, Front. Psychol. 10(May), 1-12, https://doi.org/ 10.3389/fpsyg.2019.00719.</div></div></div><div><br></div><div><div><div>Khan, S., Farnsworth, M., McWilliam, R. and Erkoyuncu, J. [2020] On the requirements of digital twin-driven autonomous maintenance, Annu. Rev. Control 50, 13-28, https://doi.org/10.1016/j.arcontrol.2020.08.003.</div></div></div><div><br></div><div><div><div>Kirk, R. [2021] Zombies, The Stanford Encyclopedia of Philosophy, Spring 202, Metaphysics Research Lab, Stanford University, https://plato.stanford.edu/archives/spr2021/entries/ zombies/.</div></div></div><div><br></div><div><div><div>Kocijan, V., Lukasiewicz, T., Davis, E., Marcus, G. and Morgenstern, L. [2020] A review of Winograd Schema Challenge datasets and approaches, http://arxiv.org/abs/2004.13831.</div></div></div><div><br></div><div><div><div>Levin, J. [2018] Functionalism, Stanford Encyclopedia of Philosophy, https://plato.stanford.edu/archives/win2021/entries/functionalism.</div></div></div><div><br></div><div><div><div>Lewis, M. [2003] The emergence of consciousness and its role in human development, Ann. New York Acad. Sci. 1001(1), 104-133, https://doi.org/10.1196/annals.1279.007.</div></div></div><div><br></div><div><div><div>Li, D., He, W. and Guo, Y. [2021] Why AI still doesn't have consciousness? CAAI Trans. Intell. Technol. 6(2), 175-179, https://doi.org/10.1049/cit2.12035.</div></div></div><div><br></div><div><div><div>Li, X., Serlin, Z., Yang, G. and Belta, C. [2019] A formal methods approach to interpretable reinforcement learning for robotic planning, Sci. Robot. 4(37), eaay6276, https://doi.org/ 10.1126/scirobotics.aay6276.</div></div></div><div><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="40" id="mark-b14aba6d-ff79-4721-8dd4-eb25c103ced6" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>Lilium [2019] The inspiration behind the Lilium Jet design, https://lilium.com/newsroom-</div></div></div><div><br></div><div><div><div>detail/from-the-oceans-to-the-skies-the-inspiration-behind-the-lilium-jet-design.</div></div></div><div><br></div><div><div><div>Linder, C. [2019] Bad news for dads: Robots can grill hot dogs now, Popular Mechanics, https://www.popularmechanics.com/technology/robots/a30298216/hotdog-cooking-robots/.</div></div></div><div><br></div><div><div><div>Locke, C. [2015] Humpback whales solve a big problem for wind turbines, Wired, https:// www.wired.com/2015/11/whales-wind-turbines/.</div></div></div><div><br></div><div><div><div>Lockheed Martin [2019] Autonomic Logistics Information System (ALIS), https://www.lockheedmartin.com/en-us/products/autonomic-logistics-information-system-alis.html.</div></div></div><div><br></div><div><div><div>Lucan, G. [2007] Jean Marie Le Bris's flying machines, Association "La Barque Ailée, https:// archive.ph/20070311062704/http://www.labarqueailee.org/english/.</div></div></div><div><br></div><div><div><div>Malone, B. [2011] George devol: A life devoted to invention, and robots, IEEE Spectrum. https://spectrum.ieee.org/george-devol-a-life-devoted-to-invention-and-robots.</div></div></div><div><br></div><div><div><div>Mansouri, A. R., Vian, J. L. and Peters, J. T. [2010]. Integrated autonomous fleet management using self-aware vehicles, US 2010/0057511 A1, https://www.freepatentsonline.com/ y2010/0057511.html.</div></div></div><div><br></div><div><div><div>McClelland, J. L. [2001] Cognitive neuroscience, in N. J. Smelser &amp; P. B. Baltes (eds.), International Encyclopedia of the Social &amp; Behavioral Sciences (Pergamon, Oxford), pp. 2133-2140, https://doi.org/https://doi.org/10.1016/B0-08-043076-7/03406-9.</div></div></div><div><br></div><div><div><div>McGovern, K. and Baars, B. J. [2007] Cognitive theories of consciousness, in P. D. Zelazo, M. Moscovitch &amp; E. Thompson (eds.), The Cambridge Handbook of Consciousness, Cambridge Handbooks in Psychology (Cambridge University Press), https://doi.org/10.1017/ CBO9780511816789.009.</div></div></div><div><br></div><div><div><div>Menon, S. [2021] Advaita vedanta, Internet Encyclopedia of Philosophy, https://iep.utm.edu/ advaita-vedanta/.</div></div></div><div><br></div><div><div><div>Montemayor, C. [2021] Types of consciousness: The diversity problem, Front. Syst. Neurosci. 15(November), 1-15, https://doi.org/10.3389/fnsys.2021.747797.</div></div></div><div><br></div><div><div><div>Nagel, T. [1974] What is it like to be a bat? Philos. Rev. 83(4), 435-450, http://www.jstor.org/stable/2183914.</div></div></div><div><br></div><div><div><div>Niikawa, T. [2020] A map of consciousness studies: Questions and approaches, Front. Psychol. 11(October), https://doi.org/10.3389/fpsyg.2020.530152.</div></div></div><div><br></div><div><div><div>OpenAI [2023] ChatGPT - Release notes, https://help.openai.com/en/articles/6825453- chatgpt-release-notes.</div></div></div><div><br></div><div><div><div>Pensworth, L. [2020] What happened to Microsoft's Tay AI chatbot? Daily Wireless, https:// dailywireless.org/internet/what-happened-to-microsoft-tay-ai-chatbot/.</div></div></div><div><br></div><div><div><div>Perry, T. S. [2017]. SRI's pioneering mobile robot Shakey honored as IEEE Milestone Shakey's creators and colleagues share inside stories at the celebration and talk about robotics today, IEEE Spectrum, https://spectrum.ieee.org/sri-shakey-robot-honored-as-ieee-milestone.</div></div></div><div><br></div><div><div><div>Polger, T. W. [2021] Functionalism, Internet Encyclopedia of Philosophy, https://iep.utm.edu/functism/.</div></div></div><div><br></div><div><div><div>Pomfret, C., Jennions, I. K. and Dibsdale, C. [2011] The business value of implementing integrated vehicle health management, in I. K. Jennions (ed.), Integrated Vehicle Health Management: Perspectives on an Emerging Field (SAE International), pp. 27-40, https:// doi.org/10.4271/R-05.</div></div></div><div><br></div><div><div><div>Reggia, J. A. [2013] The rise of machine consciousness: Studying consciousness with computational models, Neural Netw. 44, 112-131, https://doi.org/10.1016/j.neunet.2013.03.011.</div></div></div><div><br></div><div><div><div>Robinson, H. [2020] Dualism, The Stanford Encyclopedia of Philosophy, https://plato.stanford.edu/archives/fall2020/entries/dualism/.</div></div></div><div><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="41" id="mark-f20eab0d-a017-43b1-b441-626f752fc38c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><div><div>Robson, D. [2015] Blindsight: The strangest form of consciousness, BBC Future, September 28, https://www.bbc.com/future/article/20150925-blindsight-the-strangest-form-of-consciousness.</div></div></div><div><br></div><div><div><div>Rovelli, C. [2022a] Aleksander Bogdanov and Vladimir Lenin, in Helgoland (Penguin Books), pp. 103-115.</div></div></div><div><br></div><div><div><div>Rovelli, C. [2022b] Relations, in Helgoland (Penguin Books), p. 70.</div></div></div><div><br></div><div><div><div>Rovelli, C. [2022c] The world seen from within, in Helgoland (Penguin Books), pp. 150-158.</div></div></div><div><br></div><div><div><div>Ruhl, C. [2020] How the theory of mind helps us understand others, Simply Psychology, https://www.simplypsychology.org/theory-of-mind.html.</div></div></div><div><br></div><div><div><div>Safron, A. [2019] Integrated World Modeling Theory (IWMT) revisited, December.</div></div></div><div><br></div><div><div><div>Safron, A. [2020] An Integrated World Modeling Theory (IWMT) of consciousness: Combining integrated information and global neuronal workspace theories with the free energy principle and active inference framework; Toward solving the hard problem and characterizing agentic, Front. Artif. Intell. 3(June), https://doi.org/10.3389/frai.2020.00030.</div></div></div><div><br></div><div><div><div>Sanz, R. and Aguado, E. [2020] Understanding and machine consciousness, J. Artif. Intell. Conscious. 7(2), 231-244, https://doi.org/10.1142/s2705078520500137.</div></div></div><div><br></div><div><div><div>Sanz, R., López, I., Rodríguez, M. and Hernández, C. [2007]. Principles for consciousness in integrated cognitive control, Neural Netw. 20(9), 938-946, https://doi.org/10.1016/j.neunet.2007.09.012.</div></div></div><div><br></div><div><div><div>Schneider, S. [2021] Identity theory, Internet Encyclopedia of Philosophy, https://iep.utm.edu/identity/.</div></div></div><div><br></div><div><div><div>Schreiner, W. [2019] Biomimicry: A history, The Ohio State University, https://ehistory.osu.edu/exhibitions/biomimicry-a-history.</div></div></div><div><br></div><div><div><div>Scott, M. J., Verhagen, W. J. C., Bieber, M. T. and Marzocca, P. [2022]. A systematic literature review of predictive maintenance for defence fixed-wing aircraft sustainment and operations, Sensors 22(18), 7070, https://doi.org/10.3390/s22187070.</div></div></div><div><br></div><div><div><div>Senanayake, M., Senthooran, I., Barca, J. C., Chung, H., Kamruzzaman, J. and Murshed, M. [2016] Search and tracking algorithms for swarms of robots: A survey, Robot. Auton. Syst. 75, 422-434, https://doi.org/10.1016/j.robot.2015.08.010.</div></div></div><div><br></div><div><div><div>Seth, A. K. and Bayne, T. [2022] Theories of consciousness, Nat. Rev. Neurosci. 23(7), 439-452, https://doi.org/10.1038/s41583-022-00587-4.</div></div></div><div><br></div><div><div><div>Shadel, J. D. [2021] Robots are disinfecting hotels during the pandemic. It's the tip of a hospitality revolution, The Washington Post, https://www.washingtonpost.com/travel/ 2021/01/27/hotels-robots-cleaning-hospitality-covid/.</div></div></div><div><br></div><div><div><div>Signorelli, C. M. [2017] Types of cognition and its implications for future high-level cognitive machines, AAAI Technical Report SS-17-01, pp. 622-627.</div></div></div><div><br></div><div><div><div>Skrbina, D. [2021] Panpsychism, Internet Encyclopedia of Philosophy, https://iep.utm.edu/ panpsych/#: <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="281" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c223C"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo>∼</mo></math></mjx-assistive-mml></mjx-container> :text=Panpsychism is the view that,psyche (soul or mind).</div></div></div><div><br></div><div><div><div>Smith, B. [2015] Descartes and consciousness, A History of Ideas, BBC Radio 4, https://www.bbc.co.uk/programmes/p02pdc6n.</div></div></div><div><br></div><div><div><div>Starship Technologies [2022] STARSHIP. https://www.starship.xyz/.</div></div></div><div><br></div><div><div><div>Stewart, J. [2017] Don't freak over Boeing's self-flying plane - Robots already run the skies, Wired, https://www.wired.com/story/boeing-autonomous-plane-autopilot/.</div></div></div><div><br></div><div><div><div>Swiechowski, M. [2020] Game AI competitions: Motivation for the imitation game-playing competition, in Proc. 2020 Federated Conf. Computer Science and Information Systems, FedCSIS 2020, Vol. 21, pp. 155-160, https://doi.org/10.15439/2020F126.</div></div></div><div><br></div><div><div><div>Talbot, B., Dayoub, F., Corke, P. and Wyeth, G. [2021] Robot navigation in unseen spaces using an abstract map. IEEE Trans. Cogn. Develop. Syst. 13(4), 791-805, https://doi.org/ 10.1109/TCDS.2020.2993855.</div></div></div><div><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="42" id="mark-3eac3ace-d372-47c0-808f-bd0fd602f668" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div><div>Taylor, R. M. [2018] Towards intelligent adaptive human autonomy teaming: On 2018 NATO SCO HFM-300 symposium, Technical Evaluation Report.</div></div></div><div><br></div><div><div><div>Tegmark, M. [2014] Our Mathematical Universe (Penguin Books).</div></div></div><div><br></div><div><div><div>Tegmark, M. [2015] Consciousness as a state of matter, Chaos Solitons Fractals 76, 238-270, https://doi.org/10.1016/j.chaos.2015.03.014.</div></div></div><div><br></div><div><div><div>The BRAIN Initiative [2017] Overview, https://braininitiative.nih.gov/about/overview.</div></div></div><div><br></div><div><div><div>The Economist [2022] Digital twins in cockpits will help planes look after themselves, The Economist Group Limited, May, https://www.economist.com/science-and-technology/ digital-twins-in-cockpits-will-help-planes-look-after-themselves/21809110.</div></div></div><div><br></div><div><div><div>Trevarthen, C. and Reddy, V. [2007] Consciousness in infants, in The Blackwell Companion to Consciousness, pp. 37-57, https://doi.org/10.1002/9780470751466.ch4.</div></div></div><div><br></div><div><div><div>Trewavas, A. [2003] Aspects of plant intelligence, Ann. Bot. 92(1), 1-20, https://doi.org/ 10.1093/aob/mcg101.</div></div></div><div><br></div><div><div><div>UN News [2021] 193 countries adopt first-ever global agreement on the ethics of artificial intelligence, United Nations, https://news.un.org/en/story/2021/11/1106612.</div></div></div><div><br></div><div><div><div>Velcro [2022] Our timeline of innovation, Velcro HomePage, https://www.velcro.co.uk/original-thinking/our-timeline-of-innovation/.</div></div></div><div><br></div><div><div><div>Walter, S. [2021] Epiphenomenalism, Internet Encyclopedia of Philosophy, https://iep.utm.edu/epipheno/#H2.</div></div></div><div><br></div><div><div><div>Weiskrantz, L. [2007] Blindsight, Scholarpedia, https://doi.org/10.4249/scholarpedia.3047.</div></div></div><div><br></div><div><div><div>Yam, M. F., Loh, Y. C., Tan, C. S., Adam, S. K., Manan, N. A. and Basir, R. [2018] General pathways of pain sensation and the major neurotransmitters involved in pain regulation, Int. J. Mol. Sci. 19(8), https://doi.org/10.3390/ijms19082164.</div></div></div><div><br></div><div><div><div>Zeman, A. [2001] Consciousness, Brain 124(7), 1263-1289, https://doi.org/10.1093/brain/ 124.7.1263.</div></div></div><div><br></div><div><div><div>Zeman, A. [2006] What do we mean by 'conscious' and 'aware'? Neuropsychol. Rehabil. 16(4), 356-376, https://doi.org/10.1080/09602010500484581.</div></div></div></div></div></div></div>
      </body>
    </html>
  