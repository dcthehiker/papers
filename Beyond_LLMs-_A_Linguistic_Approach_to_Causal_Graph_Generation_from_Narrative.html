
    <!DOCTYPE html>
    <html lang="en">
      <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Beyond_LLMs-_A_Linguistic_Approach_to_Causal_Graph_Generation_from_Narrative</title>
        <style>
            * {
              padding: 0;
              margin: 0;
              box-sizing: border-box;
            }
             html {
              line-height: 1.15; /* 1 */
              -webkit-text-size-adjust: 100%; /* 2 */
            }
            body {
              padding: 20px;
              margin: 0;
            }
            main {
              display: block;
            }
            h1 {
              font-size: 2em;
              margin: 0.67em 0;
            }
            hr {
              box-sizing: content-box; /* 1 */
              height: 0; /* 1 */
              overflow: visible; /* 2 */
            }
            pre {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            a {
              background-color: transparent;
            }
            abbr[title] {
              border-bottom: none; /* 1 */
              text-decoration: underline; /* 2 */
              text-decoration: underline dotted; /* 2 */
            }
            b,
            strong {
              font-weight: bolder;
            }
            code,
            kbd,
            samp {
              font-family: monospace, monospace; /* 1 */
              font-size: 1em; /* 2 */
            }
            small {
              font-size: 80%;
            }
            sub,
            sup {
              font-size: 75%;
              line-height: 0;
              position: relative;
              vertical-align: baseline;
            }
            sub {
              bottom: -0.25em;
            }
            sup {
              top: -0.5em;
            }
            img {
              border-style: none;
            }
            button,
            input,
            optgroup,
            select,
            textarea {
              font-family: inherit; /* 1 */
              font-size: 100%; /* 1 */
              line-height: 1.15; /* 1 */
              margin: 0; /* 2 */
            }
            button,
            input { /* 1 */
              overflow: visible;
            }
            button,
            select { /* 1 */
              text-transform: none;
            }
            button,
            [type="button"],
            [type="reset"],
            [type="submit"] {
              -webkit-appearance: button;
            }
            button::-moz-focus-inner,
            [type="button"]::-moz-focus-inner,
            [type="reset"]::-moz-focus-inner,
            [type="submit"]::-moz-focus-inner {
              border-style: none;
              padding: 0;
            }
            button:-moz-focusring,
            [type="button"]:-moz-focusring,
            [type="reset"]:-moz-focusring,
            [type="submit"]:-moz-focusring {
              outline: 1px dotted ButtonText;
            }
            fieldset {
              padding: 0.35em 0.75em 0.625em;
            }
            legend {
              box-sizing: border-box; /* 1 */
              color: inherit; /* 2 */
              display: table; /* 1 */
              max-width: 100%; /* 1 */
              padding: 0; /* 3 */
              white-space: normal; /* 1 */
            }
            progress {
              vertical-align: baseline;
            }
            textarea {
              overflow: auto;
            }
            [type="checkbox"],
            [type="radio"] {
              box-sizing: border-box; /* 1 */
              padding: 0; /* 2 */
            }
            [type="number"]::-webkit-inner-spin-button,
            [type="number"]::-webkit-outer-spin-button {
              height: auto;
            }
            [type="search"] {
              -webkit-appearance: textfield; /* 1 */
              outline-offset: -2px; /* 2 */
            }
            [type="search"]::-webkit-search-decoration {
              -webkit-appearance: none;
            }
            ::-webkit-file-upload-button {
              -webkit-appearance: button; /* 1 */
              font: inherit; /* 2 */
            }
            details {
              display: block;
            }
            summary {
              display: list-item;
            }
            [hidden] {
              display: none;
            }
             table {
                border-collapse: collapse;
                width: 100%;
                margin-top: 20px;
                margin-bottom: 20px;
              }
              table thead {
                background-color: #e5e5e5;
              }
              table td {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              table th {
                padding: 8px;
                /*background-color: #e5e5e5;*/
                border: 1px solid #ccc; /* 可选，添加边框样式 */
              }
              h1, h2, h3, h4, h5, h6 {
                margin-bottom: 20px;
              }
              p {
                margin-top: 20px;
                text-indent: 2em;
                margin-bottom: 20px;
              }
        </style>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      </head>
      <body>
        <div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="1" id="mark-4b88561c-6e37-40d7-8a7f-078db8279468" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><h1><div><div>Beyond LLMs: A Linguistic Approach to Causal Graph Generation from Narrative Texts</div></div></h1><div><br></div><div><div><div>Zehan Li Ruhua Pan Xinyu Pi</div></div></div><div><br></div><div><div><div>University of California, San Diego</div></div></div><div><br></div><div><div><div>{zel025, r3pan, xpi}@ucsd.edu</div></div></div><div><br></div><h2><div><div>Abstract</div></div></h2><div><br></div><div><div><div>We propose a novel framework to generate causal graphs from narrative texts, bridging the gap between high-level causality and finer-grained event-specific relationships. Our approach first extracts concise, agent-centered "vertices" using an LLM-based summarization strategy. We then introduce an <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="22" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D465 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mi>E</mi><mi>x</mi></mrow></math></mjx-assistive-mml></mjx-container> - pert Index-seven linguistically grounded features-and incorporate them into a STAC (Situation, Task, Action, Consequence) classification model. This hybrid system (RoBERTa embeddings + Expert Index) achieves superior precision in identifying causal links compared to LLM-only baselines. Finally, we apply a structured, five-iteration prompting process to refine and construct a connected causal graph. Experiments on 100 chapters and short stories show that our method consistently outperforms GPT-4o and Claude 3.5 across key dimensions of causal graph quality, while maintaining comparable readability. The resulting open-source tool offers an interpretable and efficient solution for capturing nuanced causal chains within narrative texts.</div></div></div><div><br></div><h2><div><div>1 Introduction</div></div></h2><div><br></div><div><div><div>Causal research has historically leveraged knowledge graphs to explore relationships between events (JM;, 1999). Modern approaches, such as AI-driven causal graph generation, have gained prominence for their ability to summarize causal events at scale (Jaimini and Sheth, 2022; Pieper et al., 2023). However, current AI models largely focus on high-level causality (e.g., "HIV leads to AIDS"), and they fall short in capturing nuanced causal relationships in specific narratives, such as political events or historical occurrences(Donnelly, 2025). Addressing this gap, we propose a method for generating causal graphs from texts that describe discrete, event-specific narratives.</div></div></div><div><br></div><div><div><div>Understanding these finer-grained causal relationships is crucial for researchers and practitioners who analyze how certain events lead to tangible outcomes in areas like social movements, policy-making, and historical trends. By capturing causal links from narrative texts, stakehold-ers can more accurately trace the chain of events that precipitate significant changes, enabling better decision-making, deeper historical insight, and more targeted interventions. Furthermore, automated causal graph generation facilitates scalable analysis of large document collections, providing structured representations that can be easily interpreted, queried, and expanded upon.</div></div></div><div><br></div><div><div><div>Most existing methods for generating causal graphs follow a two-stage pipeline: (1) a Causality Finder to detect causal relations, and (2) a graph Generator to construct knowledge graphs from these relations. While effective, these methods face limitations in interpretability and accuracy, particularly when dealing with complex sentence structures or implicit causal links(Kıcıman et al., 2024) (Kyono et al., 2024).</div></div></div><div><br></div><div><div><div>Causality finders have evolved through three phases: (1) early pattern-based models that learned causal relationships from fixed sentence structures (Hidey and McKeown, 2016) (Heindorf et al., 2020), (2) BERT-based approaches that addressed issues in text training but failed to account for semantic context (Tan et al., 2023) (Dasgupta et al., 2018) (Li et al., 2020), and (3) LLMs, which improved contextual reasoning but struggled to distinguish intricate causal relationships (Kıcıman et al., 2024) (Shen et al., 2022) (Luo et al., 2024).</div></div></div><div><br></div><div><div><div>In this paper, we present a novel framework that leverages linguistic feature extraction to enhance causal graph generation from narrative texts. Our approach introduces a Quaternary Classification system to categorize sentences into four components: (1) Situation, (2) Task, (3) Action, and (4) Consequences. This structured decomposition allows for more precise identification of causal links. We also propose a Neural Network model trained on these linguistic features, achieving higher accuracy and interpretability compared to LLM-based methods, with lower computational costs.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="2" id="mark-0087d6a9-a33a-406a-8593-22f624b5105c" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br></div><div><div><div>Our contributions are twofold: (1) We develop an open-source, end-to-end causal graph generation model that significantly improves interpretability and accuracy. (2) We introduce a Linguistics Feature system, which efficiently classifies sentences for causal graph construction, validated through experiments on various narrative texts.</div></div></div><div><br></div><h2><div><div>2 Problem Setting</div></div></h2><div><br></div><div><div><div>This paper studies the problem of causal relationship graphs as follows. Given a narrative text, such as a story by O. Henry or a piece of narrative news, we can generate its causal relationship graph containing the main causal relationships. More specifically, when we input a set of narrative sentences <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="23" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D446 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D460 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>s</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow></math></mjx-assistive-mml></mjx-container> ,we aim to obtain a connected graph <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="24" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>V</mi><mo>,</mo><mi>E</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> to represent the structure of the story, where:</div></div></div><div><br><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="25" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>V</mi></math></mjx-assistive-mml></mjx-container> is the set of vertices,each vertex representing a major event in the story.</li></ul><br><ul><li><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="26" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>E</mi></math></mjx-assistive-mml></mjx-container> is the set of edges,where each edge <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="27" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="2"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2208"></mjx-c></mjx-mo><mjx-mi class="mjx-i" space="4"><mjx-c class="mjx-c1D438 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><mi>u</mi><mo>,</mo><mi>v</mi></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow><mo>∈</mo><mi>E</mi></math></mjx-assistive-mml></mjx-container> represents the temporal or causal relationship from event <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="28" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D462 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>u</mi></math></mjx-assistive-mml></mjx-container> to event <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="29" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>v</mi></math></mjx-assistive-mml></mjx-container> .</li></ul><br></div><div><div><div>For the definition of Edges E, We say Event A causes Event B if:</div></div></div><div><br><ul><li>(the multi-factorial definition): in combination with other factors, Event A is a necessary or a sufficient condition for Event B (Oppenheimer and Susser, 2007)</li></ul><br><ul><li>(the probabilistic definition): the occurrence of Event A raises the probability of Event B occurring (Reichenbach, 1991).</li></ul><br></div><h2><div><div>3 Methodology</div></div></h2><div><br></div><div><div><div>Our complete Causal graph Model is an End-to-End model. We hope to input any story and generate a Connected Graph <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="30" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D43A TEX-I"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi></math></mjx-assistive-mml></mjx-container> . This model contains four main parts:(1) Vertices Extraction, (2)Expert Index Extraction, (3) STAC Categorization, (4)Graph Construction.</div></div></div><div><br></div><h3><div><div>3.1 Vertices Extraction</div></div></h3><div><br></div><div><div><div>We define each vertex in our causal graph as a single event or state, represented by:</div></div></div><div><br></div><div><div><div><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="31" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D449 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mrow space="4"><mjx-mo class="mjx-n"><mjx-c class="mjx-c7B"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2026"></mjx-c></mjx-mo><mjx-mo class="mjx-n" space="2"><mjx-c class="mjx-c2C"></mjx-c></mjx-mo><mjx-msub space="2"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2223"></mjx-c></mjx-mo><mjx-msub space="4"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D463 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em;"><mjx-texatom size="s" texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D456 TEX-I"></mjx-c></mjx-mi></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-mtext class="mjx-n" space="4"><mjx-c class="mjx-cA0"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c69"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c67"></mjx-c><mjx-c class="mjx-c6C"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c20"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c76"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-c6E"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c2F"></mjx-c><mjx-c class="mjx-c73"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c61"></mjx-c><mjx-c class="mjx-c74"></mjx-c><mjx-c class="mjx-c65"></mjx-c><mjx-c class="mjx-cA0"></mjx-c></mjx-mtext></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c7D"></mjx-c></mjx-mo></mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c2E"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>V</mi><mo>=</mo><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">{</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>v</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>v</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mrow data-mjx-texclass="ORD"><mi>v</mi></mrow><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow></msub><mo>∣</mo><msub><mrow data-mjx-texclass="ORD"><mi>v</mi></mrow><mrow data-mjx-texclass="ORD"><mi>i</mi></mrow></msub><mo>=</mo><mtext>&nbsp;a single event/state&nbsp;</mtext></mrow><mo data-mjx-texclass="CLOSE">}</mo></mrow><mo>.</mo></math></mjx-assistive-mml></mjx-container> These vertices serve as Vertices capturing key information with causal relationships in the narrative. Our goal is to transform the original text into concise, event-specific sentences by leveraging a LLM and prompt engineering. In particular, we used the LangChain framework to guide the LLM in generating simple sentences that reflect core plot elements.</div></div></div><div><br></div><h2><div><div>Requirements for Each Vertex</div></div></h2><div><br><ol><li value="1">Concise: Each sentence must contain no more than two clauses.</li></ol><br><ol><li value="2">Agent-Centered: The subject (or agent) of the action must be explicitly identified, with only one subject per sentence.</li></ol><br><ol><li value="3">Active Voice: Each sentence should clearly convey an action initiated by its subject.</li></ol><br></div><div><div><div>Extraction Procedure We applied a structured prompting workflow to simplify the text into short, self-contained sentences, each representing a single narrative event:</div></div></div><div><br><ol><li value="1">Summarization: The LLM receives a paragraph and generates a brief summary, ensuring each resulting sentence is as simple as possible.</li></ol><br><ol><li value="2">Pronoun Substitution: All pronouns are replaced with explicit referents. For a first-person narrative, the speaker is replaced by a clear identifier, such as the speaker's name or `"The Protagonist"` if none is provided.</li></ol><br><ol><li value="3">Clause Simplification: Complex or compound sentences are split into multiple simple sentences, each containing one core action or state. Unimportant details that do not affect the plot are removed.</li></ol><br><ol><li value="4">Continuous Flow: The resulting sentences are checked to ensure they preserve a logical, causal flow of events, discarding irrelevant or tangential information.</li></ol><br></div><div><div><div>By enforcing these requirements and following this workflow, we derive a set of concise, agent-specific sentences-each of which becomes a vertex in our causal graph. This method preserves the essential narrative structure while ensuring that each vertex encapsulates only a single event or state.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="3" id="mark-5275b87b-95e8-4157-baa0-2a920248730f" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><!-- figureText: graph nodes Input: Summarized Text, Predicted STAC Labels Help formulate edges Stage 3: STAC Stage 4: Diagram Categorization Formulation Output: Output: Predicted STAC Causal Graph Labels 日 Input: Raw text Stage 1: Vertices Stage 2: Expert Extraction Index Extraction Output: Output: Summarized Story Text with Index --><br></div><img src="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_2.jpg?x=290&amp;y=212&amp;w=1119&amp;h=410&amp;r=0" alt="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_2.jpg?x=290&amp;y=212&amp;w=1119&amp;h=410&amp;r=0"><div><br></div><div><div><div>Figure 1: Overview of our DA framework. It is an end to end Model. First we input a Random Narrative Text. Then in Stage 1, we Contribute the Vertices of the Graph. And in Stage 2, we Use our Expert Index to indicate the Vertices. Next, In stage 3,we use a STAC system to label the Vertices. In STAGE 4, we use STAC Label + Vertices to complete the Causal Graph</div></div></div><div><br><!-- Media --><br></div><h3><div><div>3.2 Expert Index Extraction</div></div></h3><div><br></div><div><div><div>This section describes our methodology for extracting the Expert Index features from each sentence and subsequently training a model to classify them. We adopt seven key features grounded in traditional and computational linguistics literature, the full description see table 3:</div></div></div><div><br><ol><li value="1">Genericity: Determines whether the sentence's subject is specific (e.g., a person, a dog) or generic (e.g., a season, an emotion) (Becker et al., 2017; Carlson, 1980).</li></ol><br><ol><li value="2">Eventivity: Classifies the verb as dynamic (observable actions such as speaking or running) or stative (expressing states or nonaction, such as deciding or thinking) (Becker et al., 2017; Vendler, 1967).</li></ol><br><ol><li value="3">Boundedness: Identifies if a event is episodic (occurs at a specific time), habitual (recurring over time), or static (always true or in a state of being) (Becker et al., 2017; Smith, 1991).</li></ol><br><ol><li value="4">Initiativity: Distinguishes whether the subject initiates the action (has agency) or receives it (lacks agency) (Dai and Huang, 2018; Comrie, 1976).</li></ol><br><ol><li value="5">Time Start: Notes if the event begins in the past or the present relative to the narrative timeline (Dowty, 1979; Allen, 1983).</li></ol><br><ol><li value="6">Time End: Determines if the event concludes in the present or the future (Dowty, 1979; Allen, 1983).</li></ol><br><ol><li value="7">Impact: Indicates whether the event's effect persists (impact) or is entirely resolved by the time it ends (Dowty, 1979; Moens and Steedman, 1988).</li></ol><br></div><div><div><div>Except for Boundedness, which has three categories, each feature has two categories, for a total of 192 possible combinations. We refer to each resulting combination as an Expert Index. Inspired by prior work that classified sentences as episodic, habitual, or static, we adopt a more granular approach to better capture distinctions relevant to our four main narrative labels: Situation, Task, Action, and Consequence.</div></div></div><div><br></div><div><div><div>To train a model for these features, we used RoBERTa, a robustly optimized variant of BERT(Liu et al., 2019). We prepared a dataset of 750 annotated sentences from 23 short stories and novel chapters, ensuring balanced coverage of tenses and narrative types. Human evaluations served as ground truth. The model was trained separately for each of the seven features and their respective categories, enabling transparent prediction of the Expert Index for every sentence.</div></div></div><div><br></div><h3><div><div>3.3 STAC Categorization</div></div></h3><div><br></div><div><div><div>We developed the STAC model to classify narrative sentences into four categories-Situation, Task, Action, and Consequence-based on structured thinking from business management. In practice, we observed that narrative events often follow a logical flow: a change in the environment (Situation) prompts a requirement (Task), leading to an activity (Action), which in turn yields a lasting result (Consequence)(Minto, 2009). Concretely:</div></div></div><div><br><ol><li value="1">Situation: Provides background context or sets the stage for future events.</li></ol></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="4" id="mark-b7635c50-b6ec-4913-90ef-27223a40f060" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br><ol><li value="2">Task: States an explicit requirement or responsibility that must be fulfilled.</li></ol><br><ol><li value="3">Action: Indicates an activity actively performed or just completed.</li></ol><br><ol><li value="4">Consequence: Describes the outcome of a prior event that changes the state.</li></ol><br></div><div><div><div>To automatically assign these four STAC labels, we trained a model using both RoBERTa embed-dings and Expert Index features as inputs. Their relation is as follows: A.6. Specifically, we extracted each sentence's embedding from RoBERTa's default Autotokenizer (a 768-length array), capturing semantic and contextual meanings. We then one-hot encoded the Expert Index categories (non-ordinal attributes) to obtain binary vectors. By concatenating these embeddings and encoded features, we formed a comprehensive input array.</div></div></div><div><br></div><div><div><div>For classification, we used XGBoost due to its efficiency and robust performance relative to traditional models. The model was trained on human-labeled STAC categories and human-labeled Expert Index features as ground truth, with regularization techniques to avoid overfitting. Once trained, the model can predict a sentence's STAC category from its tokenized RoBERTa embedding and Expert Index attributes.</div></div></div><div><br></div><h3><div><div>3.4 Graph Construction</div></div></h3><div><br></div><div><div><div>After classifying all vertices using the STAC model-Situation, Task, Action, and Consequence-we aimed to build a causal diagram capturing the complexity of narrative events. Initially, we considered 16 possible bonds (i.e., relationships) between the four STAC categories; however, only 11 of these bonds were meaningful in the actual narrative context. Furthermore, we observed that real-world events often exhibit relationships such as Action <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="32" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> Action or Situation <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="33" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2192"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">→</mo></math></mjx-assistive-mml></mjx-container> Situation, underscoring the non-linear nature of storytelling.</div></div></div><div><br></div><div><div><div>To systematically determine the edges between vertices, we adopted a five-iteration LangChain-based prompting process. This approach refines causal relationships in stages, ensuring that each edge is relevant, logically consistent, and supported by the narrative.</div></div></div><div><br></div><div><div><div>Iteration 1: STAC Bond Learning We first prompted the LLM to internalize the STAC bonding schema, which outlines valid causal connections among Situation, Task, Action, and Consequence. By learning these inherent relationships, the model could more accurately propose potential edges in subsequent steps.</div></div></div><div><br></div><div><div><div>Iteration 2: Causal Relation Identification Next, the LLM evaluated pairs of vertices (in total <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="34" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D442 TEX-I"></mjx-c></mjx-mi><mjx-mrow space="2"><mjx-mo class="mjx-sop"><mjx-c class="mjx-c28 TEX-S1"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msup><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: 0.363em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-sop"><mjx-c class="mjx-c29 TEX-S1"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msup><mrow data-mjx-texclass="ORD"><mi>n</mi></mrow><mrow data-mjx-texclass="ORD"><mn>2</mn></mrow></msup><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mn>2</mn></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> pairs) to propose potential causal links based on the STAC bonds. At this stage, the model only suggested edges that aligned with valid STAC relationships and logically connected one event's outcome or state to another event's occurrence.</div></div></div><div><br></div><div><div><div>Iteration 3: Logical Consistency and Pruning After generating an initial set of edges, the LLM applied counterfactual reasoning-asking, "If A did not occur, would B still happen?"—to filter out any bonds that did not have explicitly causal relationship. Non-causal or weakly supported edges were systematically pruned, leaving only robust causal connections.</div></div></div><div><br></div><div><div><div>Iteration 4: Isolated Vertices Refinement In the fourth step, the LLM revisited any vertices that remained isolated (i.e., lacking causal connections). By prompting the model with a "why" question, we explored whether there were overlooked causes or effects. If new connections surfaced, they were subjected to the same scrutiny and pruning as in Iterations 2 and 3 , ensuring consistency and avoiding redundant links.</div></div></div><div><br></div><div><div><div>Iteration 5: Final Graph Construction Finally, the refined set of vertices and edges was compiled into a coherent graph that depicts the full range of causal relationships within the narrative. This final graph integrates all relevant Vertices and edges, with every link verified for logical soundness and alignment with the STAC bonding schema.</div></div></div><div><br></div><div><div><div>By iterating through these five steps, we resolved the complexities of linking narrative events-particularly cases where Action leads to another Action or Situation follows another Situation. The result is a structured causal diagram A. 5 that accurately reflects the underlying relationships dictated by both the story and the STAC framework.</div></div></div><div><br></div><h2><div><div>4 Experiment Setup</div></div></h2><div><br></div><h3><div><div>4.1 Corpus Collection</div></div></h3><div><br></div><div><div><div>We hand-collected excerpts from 50 full-length novels and 50 short stories, covering works published between 1800 and 1950. Each data selection features either one chapter from a novel or a complete short story, with lengths averaging 5,000 words. All narratives were sourced from various public domain web archives. These works were selected in part because our annotators were already familiar with the narratives, reducing ambiguity and enabling more consistent annotation.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="5" id="mark-600379a8-695d-48c7-8c09-7bca4b34afb6" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>The dataset incorporates both complete story cycles (e.g., short stories) and fragmentary narratives (e.g., chapters), allowing for comparative event-flow analysis (Sims and Bamman, 2019; Kirti et al., 2024). Thematically, it spans fairy tales, stream-of-consciousness storytelling (e.g., Poe's Berenice (Poe, 1835)), and implied-content stories (e.g., works by O. Henry (Henry, 1906)), ensuring a diverse testing ground for event-extraction models (Levi et al., 2022; Elson, 2012).</div></div></div><div><br></div><h3><div><div>4.2 Summarization and Dataset Structuring</div></div></h3><div><br></div><div><div><div>After selecting corpus material, we employ a multilayered Large Language Model (LLM) pipeline to iteratively refine narrative content, forming our finalized corpus dataset. The pipeline extracts and refines key sentences and concepts based on the story's progression, creating a connected-event narrative structure. The input to the pipeline is a raw chapter or story from the gathered corpus material, and the output is a concise summarization where each sentence has a declarative, complete narrative structure (Goyal and Durrett, 2022; Lu et al., 2023).</div></div></div><div><br></div><div><div><div>After processing each piece in the corpus through the pipeline, we gather a dataset optimized for event flowchart mapping. The final summaries, averaging under 40 sentences for each short story or novel chapter, serve as standardized Vertices in the output graph. Details on the pipeline and prompt methodology are provided in the Appendix A.1.</div></div></div><div><br></div><h3><div><div>4.3 Expert and STAC Labeling</div></div></h3><div><br></div><div><div><div>To construct the event-flow graph, we apply a structured labeling process integrating expert index classification and STAC labeling. This ensures clear labeling of narrative components into actionable event Vertices (Barth, 2021).</div></div></div><div><br></div><div><div><div>We asked ten anonymous annotators to assign expert index and STAC labeling to every sentence in the dataset. When differences arose, the mode was used (Fleiss, 1971). Annotators assigned the expert index based on predefined criteria introduced earlier. They were then instructed to assign STAC labeling to the same sentences following a hierarchical rule set:</div></div></div><div><br><ul><li>An execution of an action verb solely defines an action.</li></ul><br><ul><li>If no action verb is present, sentences implying an execution are labeled as tasks.</li></ul><br><ul><li>If a description is shaped by the main flow of events and tasks, it is a consequence.</li></ul><br><ul><li>Otherwise, it is classified as a situation.</li></ul><br></div><div><div><div>This layered process ensures consistency across the dataset, aligning narrative progression with structured event representation for final graph construction.</div></div></div><div><br></div><div><div><div>We also explored generating STAC labels and Expert Index levels using a standardized prompt driven by a Large Language Model (LLM), detailed explicitly in the Appendix A.1. However, the resulting annotation performance was suboptimal. Specifically, after evaluation across 300 datasets compared to annotations produced by human annotators, the Cohen's Kappa (Cohen, 1960; Landis and Koch, 1977) for the Expert Index generated by the LLM was found to be 0.73 , indicating good but not excellent agreement. In contrast, the Cohen's Kappa for STAC labels generated by the LLM fluctuated around 0.63 , suggesting only moderate agreement and thus inadequate for reliable model training. Consequently, for all subsequent scenarios involving Expert Index and STAC labeling, we adopted human annotations exclusively as the ground truth.</div></div></div><div><br></div><h2><div><div>5 Experiments</div></div></h2><div><br></div><h3><div><div>5.1 Vertices Extraction Result</div></div></h3><div><br></div><div><div><div>We evaluate and compare the performance of different models by comparing and rating their performances on fifteen selected stories. Ten of these were short stories, and five were chapters from well-known novels: The Giver (Lowry, 1993), The Great Gatsby (Fitzgerald, 1925), and Rebecca (Du Maurier, 1938). For each story or chapter, three summaries were generated using the same prompt and parameter settings (detailed in the Appendix A.2, A.3) with no post-editing, following standard practices for comparative evaluation of summarization models (Goyal and Durrett, 2022; Lu et al., 2023).</div></div></div><div><br></div><div><div><div>To reflect the downstream goal of transforming summaries into structured event flowcharts, we defined a three-part evaluation rubric based on existing summarization literature (Kryscinski et al., 2019; Fabbri et al., 2021):</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="6" id="mark-ff25f35d-0ea6-4fca-9dd8-6e0f195ba090" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br><ul><li>Conciseness and Sentence Structure: Clean sentence flow, minimal subordination, and avoidance of redundancy.</li></ul><br><ul><li>Coverage and Coherence: Inclusion of all key story events in proper logical order.</li></ul><br><ul><li>Information Span &amp; Economy: Avoidance of unnecessary elaboration or repeated ideas.</li></ul><br></div><div><div><div>Each summary was scored across the three dimensions <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="35" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c></mjx-mn><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n" space="3"><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>5</mn></math></mjx-assistive-mml></mjx-container> scale per category,15max per summary) by three LLM models (GPT-4o, GPT-4 Turbo, Claude 3.5), and the mean was then taken. Two additional criteria, Agent-Centered and Active Voice,were achieved at <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="36" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>100</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> by all models and thus not considered further in our analysis.</div></div></div><div><br><!-- Media --><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>Model</td><td>Concise</td><td>Cover</td><td>Info Span</td></tr><tr><td>GPT-40</td><td>4.2</td><td>4.9</td><td>4.4</td></tr><tr><td>GPT-4 Turbo</td><td>3.9</td><td>4.7</td><td>4.5</td></tr><tr><td>GPT-o1</td><td>4.1</td><td>4.4</td><td>4.2</td></tr></tbody></table></div><br></div><div><div><div>Table 1: GPT-4o demonstrates superior performance across all evaluated dimensions.</div></div></div><div><br><!-- Media --><br></div><div><div><div>These results suggest that GPT-4o consistently demonstrates superior performance, producing efficient narrative compression while retaining complete event arcs-a critical capability for generating effective, structured flowchart-ready summaries (Li et al., 2022; Sims and Bamman, 2019). Consequently, GPT-4o was selected as our primary summarization model for dataset structuring.</div></div></div><div><br></div><h3><div><div>5.2 Expert Index Result</div></div></h3><div><br></div><div><div><div>We used a RoBERTa-based classifier fine-tuned on a custom-labeled dataset of 1,000 summary-extracted sentences annotated by humans. The dataset was split <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="37" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mo class="mjx-n"><mjx-c class="mjx-c2F"></mjx-c></mjx-mo></mjx-texatom><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>80</mn></mrow><mrow data-mjx-texclass="ORD"><mo>/</mo></mrow><mrow data-mjx-texclass="ORD"><mn>20</mn></mrow></math></mjx-assistive-mml></mjx-container> into training and testing sets, with hyperparameters tuned via default cross-validation. Each trait was modeled independently as a multi-class classification task.</div></div></div><div><br></div><div><div><div>Performance scores for each trait dimension are shown in Table 5. Overall, the classifier exhibited strong performance on traits with more balanced or semantically distinct labels. Genericity, Eventivity, and Initiativity all yielded F1-scores above 0.85 on their dominant classes. Boundedness posed greater challenges due to conceptual overlap between the habitual and static classes, leading to reduced precision and recall.</div></div></div><div><br></div><div><div><div>The classifier achieved high overall accuracy across most traits, with particularly strong results for identifying Initiate vs. Receive references and dynamic event types. Errors in Boundedness are unsurprising given the theoretical overlap between habitual and static categories. For traits with label imbalance, such as retextitTime Start, outcome reveals minor reduced recall.</div></div></div><div><br></div><h3><div><div>5.3 STAC Categorization Result</div></div></h3><div><br></div><div><div><div>We conducted a series of experiments on a dataset of 1,000 ground-truth annotated sentences to evaluate the effectiveness of incorporating Expert Index features for STAC classification. Each sentence in the dataset is labeled with one of four STAC categories (Situation, Task, Action, or Consequence). We used a standard train/test split (e.g., 80/20) and report the F1-score for each category as well as the macro-averaged F1-score across all four labels. Six different classification models were compared to isolate the impact of the Expert Index (EI) features:</div></div></div><div><br><ol><li value="1">RoBERTa (sentence only) - A baseline model using only RoBERTa sentence embed-dings (768-dimensional) with a linear classifier.</li></ol><br><ol><li value="2">RoBERTa + EI - RoBERTa embeddings augmented with the 13-dimensional one-hot Expert Index vector (total 781 features) and classified by a linear layer.</li></ol><br><ol><li value="3">XGBoost (EI only) - An XGBoost classifier using only the 13 Expert Index features.</li></ol><br><ol><li value="4">XGBoost (RoBERTa only) - XGBoost using only 768-dim RoBERTa embedding as input.</li></ol><br><ol><li value="5">XGBoost (RoBERTa + EI) - XGBoost using the combined feature set of RoBERTa embedding + EI (781 features).</li></ol><br><ol><li value="6">GPT-4 (prompt-based) - Using GPT-4 directly for classification via prompt (zero-shot, without fine-tuning).</li></ol><br></div><div><div><div>As shown in Figure 2, models that incorporate the Expert Index features consistently outperform their counterparts that use only the sentence embedding. For instance, augmenting RoBERTa with the EI features raises the F1-score score in each category by at least 5 percentage points compared to using RoBERTa alone. This improvement is most pronounced for the Consequence (C) category, where the RoBERTa+EI model achieves an F1-score of about 0.68 versus 0.55 with RoBERTa-only (a 13-point gain). Even the XGBoost classifier using only the 13 EI features (without any RoBERTa embedding) performs respectably across categories <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="38" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mrow><mjx-mo class="mjx-n"><mjx-c class="mjx-c28"></mjx-c></mjx-mo><mjx-texatom texclass="ORD"><mjx-msub><mjx-texatom texclass="ORD"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D439 TEX-I"></mjx-c></mjx-mi></mjx-texatom><mjx-script style="vertical-align: -0.15em; margin-left: -0.106em;"><mjx-texatom size="s" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msub><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c2248"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c36"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c38"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom><mjx-mo class="mjx-n"><mjx-c class="mjx-c29"></mjx-c></mjx-mo></mjx-mrow></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="INNER"><mo data-mjx-texclass="OPEN">(</mo><mrow data-mjx-texclass="ORD"><msub><mrow data-mjx-texclass="ORD"><mi>F</mi></mrow><mrow data-mjx-texclass="ORD"><mn>1</mn></mrow></msub><mo>≈</mo><mrow data-mjx-texclass="ORD"><mn>0.65</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>0.80</mn></mrow></mrow><mo data-mjx-texclass="CLOSE">)</mo></mrow></math></mjx-assistive-mml></mjx-container> ,underscoring that the Expert Index captures valuable signals for the STAC classification task.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="7" id="mark-5f9e345f-48dd-424e-8021-7ffd0a3e3b36" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br><!-- Media --><br><!-- figureText: 0.9 STAC Classification: F1 Score by Label Method GPT (Sentence) RoBERTa (Sentence) RoBERTa (Sentence+EI) XGBoost (768 Emb) XGBoost (El = 13) A Overall STAC Label 0.8 F1 Score 0.6 0.5 0.3 --><br></div><img src="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_6.jpg?x=192&amp;y=193&amp;w=610&amp;h=455&amp;r=0" alt="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_6.jpg?x=192&amp;y=193&amp;w=610&amp;h=455&amp;r=0"><div><br></div><div><div><div>Figure 2: F1-score-score comparison across STAC labels for all six models. Each curve corresponds to a classification method, plotting F1-score for the four individual labels(S,T,A,C)and the overall macro-F1- score (rightmost point). The XGBoost model using both RoBERTa embeddings and Expert Index features (red curve) achieves the highest F1-score in every category.</div></div></div><div><br><!-- Media --><br></div><div><div><div>Among all evaluated models, the XGBoost ensemble leveraging the combined RoBERTa + Expert Index features is the top performer. It attains the highest F1-score in each STAC category and the highest overall macro-F1-score. Notably, this model outperforms the GPT-4 classifier by approximately <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="39" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mo class="mjx-n" space="3"><mjx-c class="mjx-c2212"></mjx-c></mjx-mo><mjx-texatom space="3" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c31"></mjx-c><mjx-c class="mjx-c35"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>10</mn></mrow><mo>−</mo><mrow data-mjx-texclass="ORD"><mn>15</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> (relative) in F1-score score,and yields about a <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="40" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c33"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom><mjx-mi class="mjx-n"><mjx-c class="mjx-c25"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mn>30</mn></mrow><mi mathvariant="normal">%</mi></math></mjx-assistive-mml></mjx-container> relative improvement over the baseline RoBERTa-only approach. These results demonstrate that incorporating the Expert Index not only consistently boosts classification accuracy for each STAC category, but that the combination of semantic embeddings with expert-driven features is especially powerful. The best model (XGBoost with RoBERTa+EI) provides a substantial performance margin over both a strong neural baseline and GPT-4, highlighting the benefit of hybridizing learned embeddings with expert knowledge.</div></div></div><div><br></div><h3><div><div>5.4 Graph Formulation Result</div></div></h3><div><br></div><div><div><div>We define eight key dimensions for evaluating the quality of a causal event graph. Each dimension captures a different aspect of how well the graph represents the narrative's causal structure:</div></div></div><div><br></div><div><div><div>Causality vs. Chronology - Does the graph emphasize true cause-effect relationships rather than merely the temporal order of events? Causal connectivity strongly shapes comprehension and recall of events (Trabasso and Van Den Broek, 1985).</div></div></div><div><br></div><div><div><div>Explicit Motivations/Intent - Are characters' goals and intentions explicitly represented as causes for their actions? Agents' motivations (the "why" for actions) reflects the intentional dimension of narratives (Zwaan and Radvansky, 1998) and ensures explanation on why events occur.</div></div></div><div><br></div><div><div><div>Granularity (Level of Detail) - Does the graph use an appropriate level of detail for events? A balanced level of detail enables both clarity and informativeness (Mulkar-Mehta et al., 2011).</div></div></div><div><br></div><div><div><div>Logical Completeness - Are all necessary causal steps and connections present to form a logically complete story? Missing links or unexplained leaps between events undermine narrative coherence (Brewer and Lichtenstein, 1982), undermining the logical soundness of the graph.</div></div></div><div><br></div><div><div><div>Hierarchy or Grouping - Does the graph organize events into higher-level groupings or hierarchical structures (e.g., subplots or phases)? A hierarchical organization (events grouped into episodes or goal-driven segments) improves understanding greatly (Mandler and Johnson, 1977).</div></div></div><div><br></div><div><div><div>Accuracy of Connections – Are the causal links in the graph correct and faithful to the story? Each connection should reflect a true causal or enabling relation in the narrative, and incorrect causal links can mislead reasoning (Pearl, 2009). Every link in the graph shall not be coincidental nor erroneous.</div></div></div><div><br></div><div><div><div>Decision Points as Branches - Does the graph explicitly show branching at decision points? Representing decision points as branch Vertices highlights the narrative's points of divergence (e.g., choices or hypothetical alternatives) and is important especially in interactive or non-linear narratives (Moser and Fang, 2012).</div></div></div><div><br></div><div><div><div>Ease of Reading - Is the graph easy to interpret visually, with a clear layout and labeling? Graph design principles (e.g., minimizing crossed links and clutter) improve human readability (Purchase, 1997), so a higher score means the graph is more reader-friendly.</div></div></div><div><br></div><div><div><div>Experimental Setup. We validated these evaluation dimensions by comparing our proposed method against strong baseline approaches, using large language models (LLMs) prompted to generate causal graphs from the same narratives. In particular, we benchmarked our method against GPT- 4o and against Claude 3.5, as representative state-of-the-art LLMs A.8. We also tested enhanced prompting with in-context examples: GPT-4o and Claude 3.5 denote prompting the LLM with 10 example narratives and their graphs (10-shot learning) to guide its generation. For each narrative text in our test set (100 narratives), both our method and a baseline LLM produced a causal graph. We then performed pairwise evaluations: for each narrative and each of the eight dimensions above, the graph from Method A was compared to the graph from Method B to decide which one was better along that specific dimension. This yields, per narrative, a binary win/loss outcome for each dimension. We conducted these pairwise comparisons for all relevant pairs: our method vs GPT-4o, our method and our method vs Claude 3.5,</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="8" id="mark-a9385064-745a-4a83-a147-5e4dfe96cf74" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><br><br><!-- Media --><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>Dimension</td><td>Our Method vs GPT-4o</td><td>Our Method vs Claude 3.5</td></tr><tr><td>Causality vs. Chronology</td><td>100%</td><td>100%</td></tr><tr><td>Explicit Motivations/Intent</td><td>95%</td><td>92%</td></tr><tr><td>Granularity (Level of Detail)</td><td>86%</td><td>84%</td></tr><tr><td>Logical Completeness</td><td>100%</td><td>100%</td></tr><tr><td>Hierarchy or Grouping</td><td>94%</td><td>92%</td></tr><tr><td>Accuracy of Connections</td><td>100%</td><td>100%</td></tr><tr><td>Decision Points as Branches</td><td>97%</td><td>95%</td></tr><tr><td>Ease of Reading</td><td>52%</td><td>57%</td></tr></tbody></table></div><br></div><div><div><div>Table 2: Win-rate of our model in pairwise comparisons against GPT-4o and Claude 3.5 on each dimension. Higher values indicate the percentage of cases where our model's graphs were preferred for that dimension.</div></div></div><div><br><!-- Media --><br></div><div><div><div>To ensure the reliability of the evaluation, we used a panel of five human annotators to judge the graph pairs dimension-by-dimension. Additionally, we employed an LLM-based evaluator (GPT-4) to perform the same pairwise judgments. We found a very high agreement between the aggregate human decisions and the LLM judge's decisions: Cohen's <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="41" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D705 TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c2E"></mjx-c><mjx-c class="mjx-c39"></mjx-c><mjx-c class="mjx-c32"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>κ</mi><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>0.92</mn></mrow></math></mjx-assistive-mml></mjx-container> for dimension-level agreement. This suggests that the LLM-based evaluation is largely consistent with human, validating its use for scaling up our evaluation. In the analysis that follows, we thus report results based on the LLM evaluator's judgments for all 100 narrative graph pairs, given the strong alignment with human annotators.</div></div></div><div><br></div><div><div><div>In Table 2, we report the win-rates of our approach's graphs compared to two baseline systems (GPT-4o and Claude 3.5) across the eight dimensions. The results show that our model substantially outperforms both baselines on almost all aspects of causal graph quality. Notably, it achieves near- 100% win rates against GPT-4o and Claude in dimensions such as Causality vs. Chronology, Logical Completeness, and Accuracy of Connections, indicating that our graphs consistently capture causal structure, completeness, and correct links better than the baseline graphs. Similarly, high win-rate margins in Explicit Motivations, Granularity, and Hierarchy/Grouping demonstrate the model's strength in including character intents, appropriate detail, and structured organization of events. In contrast, for Ease of Reading, the advantage of our model is much smaller (around 52-57% win-rate), suggesting that the clarity and readability of our graphs are roughly on par with those generated by GPT-4o and Claude. Overall, these results highlight that our proposed graph formulation provides significant improvements in most qualitative dimensions of causal graph representation, while maintaining comparable readability.</div></div></div><div><br></div><h2><div><div>6 Conclusion</div></div></h2><div><br></div><div><div><div>We have introduced a linguistics-focused, end-to-end approach for building causal graphs from narrative texts. By leveraging a lightweight Expert Index to capture seven core linguistic traits, our STAC classifier improves both interpretability and accuracy in labeling events. A specialized, multistep prompting strategy then constructs a logically consistent causal graph that outperforms GPT-4o and Claude 3.5 on most causal quality metrics. The results highlight the benefits of integrating interpretable feature engineering with modern language models for fine-grained causal reasoning. Our framework is open-source and readily adaptable for broader applications in summarization, discourse analysis, and knowledge graph construction.</div></div></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="9" id="mark-b9d25db3-7630-46de-afc2-7e23753e6208" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h2><div><div>Acknowledgments</div></div></h2><div><br></div><div><div><div>We would thank all the anonymous reviewers for their constructive feedback and insightful comments.</div></div></div><div><br></div><h2><div><div>References</div></div></h2><div><br></div><div><div><div>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM, 26(11):832-843.</div></div></div><div><br></div><div><div><div>Florian Barth. 2021. Annotation guidelines for narrative levels and narrative acts v2. Journal of Cultural Analytics.</div></div></div><div><br></div><div><div><div>Maria Becker, Magdalena Staniek, Vivi Nastase, Alexis Palmer, and Anette Frank. 2017. Classifying semantic clause types: Modeling context and genre characteristics with recurrent neural networks and attention. In Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), pages 230-240.</div></div></div><div><br></div><div><div><div>William F. Brewer and Edward H. Lichtenstein. 1982. Stories are to entertain: a structural-affect theory of stories. Journal of Pragmatics, 6(5):473-486.</div></div></div><div><br></div><div><div><div>Gregory N. Carlson. 1980. Reference to Kinds in English. Garland Publishing.</div></div></div><div><br></div><div><div><div>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):37-46.</div></div></div><div><br></div><div><div><div>Bernard Comrie. 1976. Aspect: An Introduction to the Study of Verbal Aspect and Related Problems. Cambridge University Press.</div></div></div><div><br></div><div><div><div>Zeyu Dai and Ruihong Huang. 2018. Building context-aware clause representations for situation entity type classification. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP 2018), pages 3305-3315.</div></div></div><div><br></div><div><div><div>Tirthankar Dasgupta, Rupsa Saha, Lipika Dey, and Abir Naskar. 2018. Automatic extraction of causal relations from text using linguistically informed deep neural networks. In Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue, pages 306-316.</div></div></div><div><br></div><div><div><div>Shannon Donnelly. 2025. Ai still can't answer complex questions about history, study finds.</div></div></div><div><br></div><div><div><div>David R. Dowty. 1979. Word Meaning and Montague Grammar. Reidel Publishing Company.</div></div></div><div><br></div><div><div><div>Daphne Du Maurier. 1938. Rebecca. Victor Gollancz.</div></div></div><div><br></div><div><div><div>David K. Elson. 2012. Dramabank: Annotating agency in narrative discourse. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12).</div></div></div><div><br></div><div><div><div>Alexander R Fabbri, Wojciech Kryscinski, Bryan McCann, Caiming Xiong, Richard Socher, and Dragomir Radev. 2021. Summeval: Re-evaluating summarization evaluation. In Transactions of the ACL, volume 9, pages 391-409.</div></div></div><div><br></div><div><div><div>F. Scott Fitzgerald. 1925. The Great Gatsby. Charles Scribner's Sons.</div></div></div><div><br></div><div><div><div>Joseph L Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378.</div></div></div><div><br></div><div><div><div>Tanishq Goyal and Greg Durrett. 2022. News summarization and evaluation in the era of gpt-3. In Proceedings of EMNLP, pages 4046-4059.</div></div></div><div><br></div><div><div><div>Stefan Heindorf, Yan Scholten, Henning Wachsmuth, Axel-Cyrille Ngonga Ngomo, and Martin Potthast. 2020. CauseNet: Towards a causality graph extracted from the web. In Proceedings of the 29th ACM International Conference on Information and Knowledge Management (CIKM).</div></div></div><div><br></div><div><div><div>O. Henry. 1906. The Four Million. Doubleday, Page &amp; Company.</div></div></div><div><br></div><div><div><div>Christopher Hidey and Kathleen McKeown. 2016. Identifying causal relations using parallel wikipedia articles. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1424-1433, Berlin, Germany.</div></div></div><div><br></div><div><div><div>Utkarshani Jaimini and Amit Sheth. 2022. Causalkg: Causal knowledge graph explainability using interventional and counterfactual reasoning. Preprint, arXiv:2201.03647.</div></div></div><div><br></div><div><div><div>Greenland S;Pearl J;Robins JM;. 1999. Causal diagrams for epidemiologic research.</div></div></div><div><br></div><div><div><div>Chaitanya Kirti, Ayon Chattopadhyay, Ashish Anand, and Prithwijit Guha. 2024. Enhancing event extraction from short stories through contextualized prompts. arXiv preprint arXiv:2412.10745.</div></div></div><div><br></div><div><div><div>Wojciech Kryscinski, Romain Paulus, Caiming Xiong, and Richard Socher. 2019. Neural text summarization: A critical evaluation. arXiv preprint arXiv:1908.08960.</div></div></div><div><br></div><div><div><div>Trent Kyono, Yao Zhang, and van der Schaar Mihaela. 2024. Neural causal graph for interpretable and inter-venable classification. In Proceedings of the Twelfth International Conference on Learning Representations (ICLR 2024).</div></div></div><div><br></div><div><div><div>Emre Kıcıman, Robert Ness, Amit Sharma, and Chen-hao Tan. 2024. Causal reasoning and large language models: Opening a new frontier for causality. Preprint, arXiv:2305.00050.</div></div></div><div><br></div><div><div><div>J Richard Landis and Gary G Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, pages 159-174.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="10" id="mark-c74e3808-e1e7-4ae3-a05f-ca4131f60435" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>Effi Levi, Guy Mor, Tamir Sheafer, and Shaul R. Shen-</div></div></div><div><br></div><div><div><div>hav. 2022. Detecting narrative elements in informational text. arXiv preprint arXiv:2210.03028.</div></div></div><div><br></div><div><div><div>Zhen Li, Yijia Liu, Yue Zhang, and Ting Liu. 2022. Title2event: Benchmarking open event extraction with a large-scale chinese title dataset. arXiv preprint arXiv:2211.00869.</div></div></div><div><br></div><div><div><div>Zhongyang Li, Xiao Ding, Ting Liu, J. Edward Hu, and Benjamin Van Durme. 2020. Guided generation of cause and effect. In Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI).</div></div></div><div><br></div><div><div><div>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.</div></div></div><div><br></div><div><div><div>Lois Lowry. 1993. The Giver. Houghton Mifflin Harcourt.</div></div></div><div><br></div><div><div><div>Xingxing Lu, Yuning Mao, and Jason Wei. 2023. Auto-eval: Llm-based automatic evaluation framework for text summarization. In Findings of ACL.</div></div></div><div><br></div><div><div><div>Kun Luo, Tong Zhou, Yubo Chen, Jun Zhao, and Kang Liu. 2024. Open event causality extraction by the assistance of llm in task annotation, dataset, and method. In Proceedings of the LREC 2024 Workshop on Bridging Neurons and Symbols for NLP and Knowledge Graphs Reasoning, pages 33-44.</div></div></div><div><br></div><div><div><div>Jean M. Mandler and Nancy S. Johnson. 1977. Remembrance of things parsed: Story structure and recall. Cognitive Psychology, 9(1):111-151.</div></div></div><div><br></div><div><div><div>Barbara Minto. 2009. The Pyramid Principle: Logic in Writing and Thinking, 3rd edition. Pearson Education, London, UK.</div></div></div><div><br></div><div><div><div>Marc Moens and Mark Steedman. 1988. Temporal ontology and temporal reference. Computational Linguistics, 14(2):15-28.</div></div></div><div><br></div><div><div><div>Christopher Moser and Xiaowen Fang. 2012. Effects of narrative structure and salient decision points in roleplaying games. In Proceedings of the 18th Americas Conference on Information Systems (AMCIS), Seattle, WA.</div></div></div><div><br></div><div><div><div>Rutu Mulkar-Mehta, Jerry R. Hobbs, and Eduard Hovy. 2011. Granularity in natural language discourse. In Proceedings of the 9th International Conference on Computational Semantics (IWCS), pages 195-199.</div></div></div><div><br></div><div><div><div>Gerald M. Oppenheimer and Ezra Susser. 2007. Invited commentary: The context and challenge of von pettenkofer's contributions to epidemiology.</div></div></div><div><br></div><div><div><div>Judea Pearl. 2009. Causality: Models, Reasoning, and Inference, 2nd edition. Cambridge University Press, Cambridge, UK.</div></div></div><div><br></div><div><div><div>Sven Pieper, Carl Willy Mehling, Dominik Hirsch, Tobias Lüke, and Steffen Ihlenfeldt. 2023. causalgraph: A python package for modeling, persisting and visualizing causal graphs embedded in knowledge graphs. Preprint, arXiv:2301.08490.</div></div></div><div><br></div><div><div><div>Edgar Allan Poe. 1835. Berenice. Southern Literary Messenger.</div></div></div><div><br></div><div><div><div>Helen C. Purchase. 1997. Which aesthetic has the greatest effect on human understanding? In Graph Drawing (Proc. 5th Int. Symposium, GD '97), volume 1353 of Lecture Notes in Computer Science, pages 248- 261, Berlin, Heidelberg. Springer.</div></div></div><div><br></div><div><div><div>Hans Reichenbach. 1991. The Direction of Time, volume 65. Univ of California Press.</div></div></div><div><br></div><div><div><div>Shirong Shen, Heng Zhou, Tongtong Wu, and Guilin Qi. 2022. Event causality identification via derivative prompt joint learning. In Proceedings of the 29th International Conference on Computational Linguistics (COLING), pages 2288-2299.</div></div></div><div><br></div><div><div><div>Matthew Sims and David Bamman. 2019. Literary event detection. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.</div></div></div><div><br></div><div><div><div>Carlota S. Smith. 1991. The Parameter of Aspect. Kluwer Academic Publishers.</div></div></div><div><br></div><div><div><div>Fiona Anting Tan, Xinyu Zuo, and See-Kiong Ng. 2023. Unicausal: Unified benchmark and repository for causal text mining. Preprint, arXiv:2208.09163.</div></div></div><div><br></div><div><div><div>Tom Trabasso and Paul Van Den Broek. 1985. Causal thinking and the representation of narrative events. Journal of Memory and Language, 24(5):612-630.</div></div></div><div><br></div><div><div><div>Zeno Vendler. 1967. Linguistics in Philosophy. Cornell University Press.</div></div></div><div><br></div><div><div><div>Rolf A. Zwaan and Gabriel A. Radvansky. 1998. Situation models in language comprehension and memory. Psychological Bulletin, 123(2):162-185.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="11" id="mark-0e03fc41-6b3c-4512-9f6e-8799433a029a" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><h2><div><div>A Appendix</div></div></h2><div><br></div><h3><div><div>A.1 LLM Prompt for Vertices Extraction</div></div></h3><div><br><ol><li value="1">I will input a paragraph to you and you need to do the following.</li></ol><br><ol><li value="2">You should summarize the sentences. All sentences should be SIMPLE sentences.</li></ol><br><ol><li value="3">If the story is told in first person POV, try to find out the speaker's name or something to refer to the speaker. If you really can't find anything, sub the speaker with 'The Protagonist'.</li></ol><br><ol><li value="4">Then, sub ALL pronouns, including the ones in the sentence, with the thing that they refer to.</li></ol><br><ol><li value="5">Then, Break ALL clauses into SIMPLE SENTENCES. Delete unimportant clause-level information. Be CONCISE.</li></ol><br><ol><li value="6">Your output at this time shall have LITTLE TO NO clauses.</li></ol><br><ol><li value="7">You need to check the sentences. If they contain clause, BREAK IT INTO TWO SENTENCES.</li></ol><br><ol><li value="8">The sentences, in their order, should give a continuous flow. DO NOT eliminate any important information that shows causal relationship.</li></ol><br><ol><li value="9">However, only information that pushes the plot/story is needed. Be concise and do not include ANY irrelevant information.</li></ol><br><ol><li value="10">Eventually, give me a summarization that focuses on causal relationships for the story.</li></ol><br></div><h3><div><div>A.2 LLM Prompt for STAC Categorization (Unused)</div></div></h3><div><br></div><div><div><div>The following is our perspective on prompting as described in Section 4, specifically in Subsection 4.3. We attempted direct prompting using the STAC Model as we understood it; however, it did not serve as a suitable baseline. Instead, we employed it solely for comparison purposes.</div></div></div><div><br></div><div><div><div>Classify each sentence in each chunk individually into either a situation, a task, an action or a consequence. Note that the sentences ARE NOT related. We do these as follows:</div></div></div><div><br><ol><li value="1">Situation: Something that sets the stage of the BACKGROUND, without implying a particular action or task. The sentence will typically set the stage for something that happens later. Generally, it focuses on things that already happened at a certain stage of the story or something that would impact stuff later.</li></ol><br><ol><li value="2">Task: Describes an explicit requirement, want, or responsibility that needs to be fulfilled. The sentence would explicitly(the action's name shall be mentioned) mention some event that one subject would accomplish later,</li></ol><br></div><div><div><div>but hasn't accomplished yet. If the sentence implies an action due to outforce changes, it's categorized as a situation.</div></div></div><div><br><ol><li value="3">Action: This refers to an activity that is BEING or HAS JUST BEEN carried out by someone. It requires someone to ACTIVELY do the action. Otherwise, it shall be a situation or a consequence.</li></ol><br><ol><li value="4">Consequence: Describes when something happens as a result of at least one thing prior AND has an everlasting impact. It's always an action that 'finishes' (the action changed some state and does not normally change back) or a straightforward state change. It's different from a situation by the fact that it should be a result of something mentioned before in the paragraph, whereas a situation happens spontaneously.</li></ol><br></div><h3><div><div>A.3 LLM Prompt for Expert Index Extraction (Unused)</div></div></h3><div><br></div><div><div><div>The following is our perspective on prompting as described in Section 4, specifically in Subsection 4.3. We attempted direct prompting using the Expert Index Model as we understood it; however, it did not serve as a suitable baseline. So we used humans as the Baseline.</div></div></div><div><br></div><div><div><div>IMPACT: I would give you a bunch of sentences and I want you to tell if the main event in the sentence has a lasting impact or if the main event is already resolved. for instance: - the door is left opened - impactful, focuses on shifting of door's state -He opened the door. - resolved, focuses on the person Border cases: - If you cannot determine any main event from the sentence, mark it as resolved because of a lack of state of change.</div></div></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="12" id="mark-4ff280c0-c593-42d0-a673-ae078ddfef15" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br></div><div><div><div>BOUNDEDNESS: I would give you a bunch of sentences, not in any order, and i want you to tell if the sentence's time span, labeled as 'Episodic', 'Habitual', or "Static'.</div></div></div><div><br></div><div><div><div>They are defined as follows: - The event is Episodic if it happens only once And is at a specific time period (you may not know that period, but you know the period exists and has</div></div></div><div><br></div><div><div><div>a bound) - The Event is Habitual if the event happens on a regular basis. (There isn't a bound. The event is constant with intervals). - The Event is Static if the Event describes a characteristic of the subject or if the event is constant and doesn't not have a clear bound. (Lacking Past OR future bound satisfies the category ).</div></div></div><div><br></div><div><div><div>SPECIFICITY: I would give you a bunch of sentences, not in any order, and i want you to tell if the sentence has a proper noun or a common noun main subject, labeled as 'Specific' or 'Generic'. Define Strictly on the subject, not the implied subject.</div></div></div><div><br></div><div><div><div>They are defined as follows: - All proper nouns are Specific. We Treat 'The Protagonist' and Any type of PRONOUNS as proper nouns in this case and are therefore Specific. Anything in First person POV is Specific. - Anything you can point to as 'It is THE ONE thing that does it' is Specific and treated as a proper noun. In a fairy tale, The Duck or A Tiger would be Specific because though they are not given a name, they act like proper nouns. (Think it like how the tiger's name would be Tiger) - As an addition to 2 , any live thing or personified thing the Starts with 'the' are treated as proper nouns and are thus Specific. - A common noun, when can STRICTLY trace back to proper noun</div></div></div><div><br></div><div><div><div>EVENTIVITY: I will give you a bunch of sentences. Classify each sentence in each chunk into either Stative, Dynamically Active or Mentally Active. Do these as follows: Check if the sentence describes a stative action (Labeled Stative). This includes possession(Have, consist, contain, etc.), thoughts(Think, remember, suspect, realize, etc.), senses(Feel, seem. etc.), and emotions that do not trigger an action (like, dislike, appreciate, etc.)</div></div></div><div><br></div><div><div><div>Or the sentence describes a dynamic action (Labeled Dynamically Active, which is characterized by more physical than mental movement). This includes the majority of the verbs(Jump, Walk, Suggest, Answer, etc.). Note that Talking or Expressing an opinion would be a dynamic action, because no mental action actually takes place.</div></div></div><div><br></div><div><div><div>Or a mental action (Labeled Mentally Active). This includes action that happens mentally rather than physically, like decide, want, desire, hope, etc.</div></div></div><div><br></div><div><div><div>TIME END: Classify each sentence in each chunk into either Time End Current (Label as C), Or Time End Future (Label as F).</div></div></div><div><br></div><div><div><div>We do these as follows: Check if the Events will be continue happened after the sentence end itslef (In this case we label F(Future)) Def of End Future: A conclusion about what is happening now (Things will continue [according to logic]) (Things will continue [for sure]) Things don't end with the statement.</div></div></div><div><br></div><div><div><div>TIME START: Classify each sentence in each chunk into either Time Start Past, Or Time Start Now. We do these as follows: Check if the Events happened as we stated (In this case we label C(Current)) or the events happened as the sentences happened before (In this case we label P(Past))</div></div></div><div><br></div><div><div><div>If you find the event being persistent or stative and therefore does not have an explicitly start time, treat its start time as infinitely in the past and therefore label it as P.</div></div></div><div><br></div><div><div><div>INITIATIVE: I would give you a bunch of sentences, not in any order, and i want you to tell if the sentence represents an action it initiates or Receives. Define the main action and the main target through common sense and content. (NOT the subject). Now, I want you to tell me whether the target actively does(initiate), or receives an action(Receive). If the sentence itself is in passive form, it's automatically Receive. If the sentence itself is in active form, think about if the subject is able to do the action out of CHOICE or the action spontaneously happens. If the subject consciously does the action, it's an Initiate action. If not so, the subject Receives the action.</div></div></div><div><br></div><div><div><div>app:STAC Categorization Unused</div></div></div><div><br></div><div><div><div>A. 4 Table Description for the Expert Index</div></div></div><div><br></div><div><div><div>A. 5 Example Graph of Our Method</div></div></div><div><br></div><div><div><div>A. 6 Table Description for STAC Bonding</div></div></div><div><br></div><div><div><div>A. 7 Expert Index Result</div></div></div><div><br></div><div><div><div>A. 8 Evaluation of Causal Graph Prompt</div></div></div><div><br></div><div><div><div>Input Story: xxxxX Causal Graph 1: xxxxxx Causal Graph 2: xxxxxx</div></div></div><div><br></div><div><div><div>Your job is to make judgement for each of the Causal Graph, determine which one is better in each of the dimension, here is the dimension description:</div></div></div><div><br><ol><li value="1">Causality vs. Chronology: Does the diagram emphasize actual cause-and-effect rather than merely stringing events in time?</li></ol><br><ol><li value="2">Explicit Motivations/Intent: Are the driving reasons (e.g., revenge, pride, fear) clearly shown so the reader sees why a character or force triggers the next event?</li></ol><br><ol><li value="3">Accuracy of Connections: Do arrows represent</li></ol></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="13" id="mark-9eea1f81-dc90-4944-a78d-d19ce0e155b6" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><br><br><!-- Media --><br><div class="table-container"><table class="fixed-table"><tbody><tr><td>Features Name</td><td>Categories</td><td>Detail</td></tr><tr><td rowspan="2">Generality</td><td>Specific</td><td>Refers to a particular instance or indi- vidual (e.g., a person, a dog).</td></tr><tr><td>Generic</td><td>Refers to a general class or category (e.g., seasons, emotions).</td></tr><tr><td rowspan="2">Eventivity</td><td>Dynamic</td><td>Involves an observable action or change (e.g., speaking, running).</td></tr><tr><td>Stative</td><td>Describes a state of being or condition (e.g., deciding, thinking).</td></tr><tr><td rowspan="3">Boundness</td><td>Episodic</td><td>Refers to an event occurring at a specific time.</td></tr><tr><td>Habitual</td><td>Refers to actions that recur over time.</td></tr><tr><td>Static</td><td>Refers to something that is always true or a permanent state.</td></tr><tr><td rowspan="2">Time Start</td><td>Past</td><td>The event began in the past relative to the narrative moment.</td></tr><tr><td>Current</td><td>The event begins in the present relative to the narrative moment.</td></tr><tr><td rowspan="2">Time End</td><td>Current</td><td>The event concludes in the present rela- tive to the narrative moment.</td></tr><tr><td>Future</td><td>The event will conclude in the future relative to the narrative moment.</td></tr><tr><td rowspan="2">Initiality</td><td>Initiate</td><td>The subject has agency and initiates the action.</td></tr><tr><td>Receive</td><td>The subject passively receives the ac- tion, without agency.</td></tr><tr><td rowspan="2">Impact</td><td>Impactful</td><td>The event has a lasting or significant effect.</td></tr><tr><td>Resolved</td><td>The event's effect diminishes or re- solves once completed.</td></tr></tbody></table></div><br></div><div><div><div>Table 3: Table Description for the Expert Index</div></div></div><div><br><!-- Media --><br></div><hr><div><br></div><div><div><div>	genuine causal links ( A enables or drives</div></div></div><div><div><div>	B), and are there any missing or spurious</div></div></div><div><div><div>	connections?</div></div></div><div><ol><li value="4">Clarity and Brevity of Nodes: Are node</li></ol></div><div><div><div>	labels concise and unambiguous? Too much</div></div></div><div><div><div>	text can clutter the diagram and obscure</div></div></div><div><div><div>	the causal flow.</div></div></div><div><ol><li value="5">Granularity/Level of Detail:Is the diagram</li></ol></div><div><div><div>	capturing just enough detail to show</div></div></div><div><div><div>	cause-effect without trivial or irrelevant</div></div></div><div><div><div>	steps?</div></div></div><div><ol><li value="6">Logical Completeness: Does it include all</li></ol></div><div><div><div>	critical causes and effects for key outcomes,</div></div></div><div><div><div>	so nothing pivotal is left out?</div></div></div><div><br></div><hr><div><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="14" id="mark-a8aec884-bdc1-4941-8d21-3eea95d45179" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><!-- Media --><br><!-- figureText: Two swindlers claimed to 'An emperor was very fond of attire.'S Two swindlers want to deceive the emperor for wealth. T The swindlers took silk and gold thread for themselves.'A The swindlers asked for more money and materials.'A The Emperor wants to see who are unfit in the kingdom. T The Emperor wanted these clothes. T The Emperor paid the swindlers a large sum.'A the progress.'T old minister to see the cloth. T The minister saw nothing but pretended to see.'A The minister reported delight 'Another official was sent to He also saw nothing but praised the cloth.'A The Emperor decided to see the cloth himself. T The town realized the Emperor was naked. "C weave magnificent fabrics.'S The fabrics were invisible to The swindlers pretended to the unfit or stupid.'S weave on empty looms. A The officials praised the empty looms.'S The Emperor saw nothing but pretended to see.'A The Emperor planned to wear the clothes in a procession. T The swindlers pretends to dress the Emperor in new clothes. \( {}^{1} \) A The procession began with the Emperor in new clothes. A 'People praised the Emperor's A child said the Emperor had clothes.'A nothing on.'A The Emperor suspected the truth but continued the procession. 'C --><br></div><img src="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_13.jpg?x=386&amp;y=174&amp;w=898&amp;h=1814&amp;r=0" alt="https://cdn.noedgeai.com/01964cd7-7d79-7913-8dd6-d55f3abe8fbe_13.jpg?x=386&amp;y=174&amp;w=898&amp;h=1814&amp;r=0"><div><br></div><div><div><div>Figure 3: Example Graph Generation of Emperor's Cloth</div></div></div><div><br><br></div></span></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="15" id="mark-49f18828-43c0-46d6-ba05-63ef93d32bb0" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><div><div class="table-container"><table class="fixed-table"><tbody><tr><td>Begin Vertices</td><td>End Vertices</td><td>Definition</td></tr><tr><td rowspan="4">Situation</td><td>Situation</td><td>The first situation may create a set- ting that directly influences or causes a change in another situation without any intermediate actions or tasks.</td></tr><tr><td>Task</td><td>The current environment imposes cer- tain responsibilities or actions on the agent.</td></tr><tr><td>Action</td><td>The environment itself drives the behav- ior, without an explicit task being iden- tified first.</td></tr><tr><td>Consequence</td><td>The scenarios where background fac- tors alone create significant changes in the state of affairs.</td></tr><tr><td rowspan="2">Task</td><td>Action</td><td>This bond is a direct relationship where the execution of a task leads to a specific action.</td></tr><tr><td>Consequence</td><td>In this bond, task itself will make an environment change as a result.</td></tr><tr><td rowspan="2">Action</td><td>Task/Action</td><td>This bond describes a sequence where one action leads directly to another ac- tion. Represents chains of immediate, active responses.</td></tr><tr><td>Consequence</td><td>This bond reflects a causal relationship where an act brings about a lasting change or outcome.</td></tr><tr><td rowspan="3">Consequence</td><td>Situation</td><td>The consequence of a previous action or event sets up a new situation.(Different environment change)</td></tr><tr><td>Task/Action</td><td>The consequence directly drives the agent's next move.</td></tr><tr><td>Consequence</td><td>This bond reflects a sequence of cascad- ing outcomes, where one consequence leads to another.</td></tr></tbody></table></div><br></div><div><div><div>Table 4: Table Description for STAC Bonding</div></div></div><div><br><br></div></div></div></div></div><div><div class="relative cursor-pointer md-tranlate-menu-layout"><div data-page="16" id="mark-7adc98fe-f8ea-4aec-870b-3eab717691a8" class="markdown-parser-view mb-5 relative cursor-pointer"><div style="height: auto;"><span style="display: inline;"><div><div class="table-container"><table class="fixed-table"><tbody><tr><td>Label</td><td>Precision</td><td>Recall</td><td><mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="42" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-texatom texclass="ORD"><mjx-texatom texclass="ORD"><mjx-mi class="mjx-b"><mjx-c class="mjx-c1D405 TEX-B"></mjx-c></mjx-mi><mjx-mn class="mjx-b"><mjx-c class="mjx-c1D7CF TEX-B"></mjx-c></mjx-mn></mjx-texatom></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow data-mjx-texclass="ORD"><mrow data-mjx-texclass="ORD"><mi mathvariant="bold">F</mi><mn mathvariant="bold">1</mn></mrow></mrow></math></mjx-assistive-mml></mjx-container></td></tr><tr><td>Genericity (Generic)</td><td>0.72</td><td>0.58</td><td>0.64</td></tr><tr><td>Genericity (Specific)</td><td>0.93</td><td>0.96</td><td>0.94</td></tr><tr><td>Eventivity (D.Active)</td><td>0.94</td><td>0.93</td><td>0.93</td></tr><tr><td>Eventivity (M.Active)</td><td>0.68</td><td>0.92</td><td>0.7</td></tr><tr><td>Eventivity (Stative)</td><td>0.85</td><td>0.75</td><td>0.80</td></tr><tr><td>Boundedness (Ep.)</td><td>0.92</td><td>0.88</td><td>0.90</td></tr><tr><td>Boundedness (Hab.)</td><td>0.31</td><td>0.36</td><td>0.33</td></tr><tr><td>Boundedness (Static)</td><td>0.73</td><td>0.80</td><td>0.76</td></tr><tr><td>Initiativity (Initiate)</td><td>0.91</td><td>0.89</td><td>0.90</td></tr><tr><td>Initiativity (Receive)</td><td>0.84</td><td>0.86</td><td>0.85</td></tr><tr><td>Time End (Present)</td><td>0.92</td><td>0.86</td><td>0.89</td></tr><tr><td>Time End (Future)</td><td>0.63</td><td>0.78</td><td>0.69</td></tr><tr><td>Time Start (Past)</td><td>0.96</td><td>1.00</td><td>0.98</td></tr><tr><td>Time Start (Present)</td><td>1.00</td><td>0.60</td><td>0.73</td></tr><tr><td>Impact (Impactful)</td><td>0.88</td><td>0.76</td><td>0.82</td></tr><tr><td>Impact (Resolved)</td><td>0.84</td><td>0.89</td><td>0.87</td></tr></tbody></table></div><br></div><div><div><div>Table 5: Classification results (test set, <mjx-container class="MathJax CtxtMenu_Attached_0" jax="CHTML" tabindex="0" ctxtmenu_counter="43" style="font-size: 119%; position: relative;"><mjx-math class="MJX-TEX" aria-hidden="true"><mjx-mi class="mjx-i"><mjx-c class="mjx-c1D45B TEX-I"></mjx-c></mjx-mi><mjx-mo class="mjx-n" space="4"><mjx-c class="mjx-c3D"></mjx-c></mjx-mo><mjx-texatom space="4" texclass="ORD"><mjx-mn class="mjx-n"><mjx-c class="mjx-c32"></mjx-c><mjx-c class="mjx-c30"></mjx-c><mjx-c class="mjx-c30"></mjx-c></mjx-mn></mjx-texatom></mjx-math><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>n</mi><mo>=</mo><mrow data-mjx-texclass="ORD"><mn>200</mn></mrow></math></mjx-assistive-mml></mjx-container> ) for each trait and class label.</div></div></div><div><br><!-- Media --></div></span></div></div></div></div>
      </body>
    </html>
  